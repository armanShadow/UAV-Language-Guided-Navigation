2025-03-26 03:30:38,748 - training - INFO - Overriding batch size with command-line value: 7
2025-03-26 03:30:38,749 - training - INFO - Overriding gradient accumulation steps with command-line value: 3
2025-03-26 03:30:38,749 - training - INFO - Starting training with debugging enabled. Error file: /tmp/torch_elastic_error_i1ds20nu.log
2025-03-26 03:30:38,749 - training - INFO - Process information: Rank 0, Local Rank 0, World Size 8
2025-03-26 03:30:38,749 - training - INFO - Device: cuda:0
2025-03-26 03:30:39,646 - training - INFO - Training on 9 GPUs, distributed mode: True
2025-03-26 03:30:39,646 - training - INFO - Starting dataset preprocessing on rank 0...
2025-03-26 03:30:39,646 - training - INFO - Starting dataset preprocessing (this will run only once)...
2025-03-26 03:30:39,648 - training - INFO - Preprocessed data already exists at /app/datasets/processed_dataset.pkl. Skipping preprocessing.
2025-03-26 03:30:39,648 - training - INFO - Dataset preprocessing complete. Took 0.00 seconds.
2025-03-26 03:30:44,200 - training - INFO - Starting model initialization...
2025-03-26 03:30:55,387 - training - INFO - Dataset split: 2466 training, 137 validation, 137 test samples
2025-03-26 03:30:55,606 - training - INFO - Test dataset indices saved to /app/UAV-Language-Guided-Navigation/AnsweringAgent/outputs/logs/test_indices.pt
2025-03-26 03:30:55,607 - training - INFO - Per-GPU batch size: 7 (effective batch size: 168, with gradient_accumulation_steps=3)
2025-03-26 03:30:55,631 - training - INFO - Created 24 gradient buckets for efficient all-reduce
2025-03-26 03:30:55,635 - training - INFO - Starting epoch 1/200000
2025-03-26 03:31:00,272 - training - INFO - Memory: GPU 0: 2622.1MB allocated, 6558.0MB reserved
2025-03-26 03:31:00,273 - training - INFO - Epoch: 1/200000, Batch: 0/45, Loss: 11.0811, Throughput: 12.08 samples/sec
2025-03-26 03:31:11,014 - training - INFO - Memory: GPU 0: 3793.7MB allocated, 9092.0MB reserved
2025-03-26 03:31:11,016 - training - INFO - Epoch: 1/200000, Batch: 15/45, Loss: 11.1911, Throughput: 58.27 samples/sec
2025-03-26 03:31:21,645 - training - INFO - Memory: GPU 0: 3799.4MB allocated, 9092.0MB reserved
2025-03-26 03:31:21,645 - training - INFO - Epoch: 1/200000, Batch: 30/45, Loss: 11.1825, Throughput: 66.75 samples/sec
2025-03-26 03:31:33,051 - training - INFO - Epoch 1 completed in 37.42s. Average loss: 11.1786
2025-03-26 03:31:33,055 - training - INFO - Starting epoch 2/200000
2025-03-26 03:31:33,778 - training - INFO - Memory: GPU 0: 3795.9MB allocated, 8882.0MB reserved
2025-03-26 03:31:33,778 - training - INFO - Epoch: 2/200000, Batch: 0/45, Loss: 11.1819, Throughput: 77.64 samples/sec
2025-03-26 03:31:44,568 - training - INFO - Memory: GPU 0: 3806.3MB allocated, 9204.0MB reserved
2025-03-26 03:31:44,568 - training - INFO - Epoch: 2/200000, Batch: 15/45, Loss: 11.0016, Throughput: 77.84 samples/sec
2025-03-26 03:31:55,270 - training - INFO - Memory: GPU 0: 3807.6MB allocated, 9204.0MB reserved
2025-03-26 03:31:55,271 - training - INFO - Epoch: 2/200000, Batch: 30/45, Loss: 10.9144, Throughput: 78.15 samples/sec
2025-03-26 03:32:05,313 - training - INFO - Epoch 2 completed in 32.26s. Average loss: 10.8584
2025-03-26 03:32:05,316 - training - INFO - Starting epoch 3/200000
2025-03-26 03:32:06,040 - training - INFO - Memory: GPU 0: 3799.1MB allocated, 9328.0MB reserved
2025-03-26 03:32:06,041 - training - INFO - Epoch: 3/200000, Batch: 0/45, Loss: 10.3605, Throughput: 77.42 samples/sec
2025-03-26 03:32:16,929 - training - INFO - Memory: GPU 0: 3805.7MB allocated, 9190.0MB reserved
2025-03-26 03:32:16,930 - training - INFO - Epoch: 3/200000, Batch: 15/45, Loss: 10.4139, Throughput: 77.17 samples/sec
2025-03-26 03:32:27,479 - training - INFO - Memory: GPU 0: 3803.3MB allocated, 9190.0MB reserved
2025-03-26 03:32:27,480 - training - INFO - Epoch: 3/200000, Batch: 30/45, Loss: 10.2956, Throughput: 78.33 samples/sec
2025-03-26 03:32:37,408 - training - INFO - Epoch 3 completed in 32.09s. Average loss: 10.1960
2025-03-26 03:32:37,420 - training - INFO - Starting epoch 4/200000
2025-03-26 03:32:38,138 - training - INFO - Memory: GPU 0: 3803.5MB allocated, 9316.0MB reserved
2025-03-26 03:32:38,139 - training - INFO - Epoch: 4/200000, Batch: 0/45, Loss: 9.7646, Throughput: 78.10 samples/sec
2025-03-26 03:32:48,923 - training - INFO - Memory: GPU 0: 3801.3MB allocated, 9074.0MB reserved
2025-03-26 03:32:48,924 - training - INFO - Epoch: 4/200000, Batch: 15/45, Loss: 9.6335, Throughput: 77.91 samples/sec
2025-03-26 03:32:59,490 - training - INFO - Memory: GPU 0: 3801.6MB allocated, 9076.0MB reserved
2025-03-26 03:32:59,490 - training - INFO - Epoch: 4/200000, Batch: 30/45, Loss: 9.4867, Throughput: 78.66 samples/sec
2025-03-26 03:33:09,401 - training - INFO - Epoch 4 completed in 31.98s. Average loss: 9.3321
2025-03-26 03:33:09,404 - training - INFO - Starting epoch 5/200000
2025-03-26 03:33:10,101 - training - INFO - Memory: GPU 0: 3799.4MB allocated, 9200.0MB reserved
2025-03-26 03:33:10,101 - training - INFO - Epoch: 5/200000, Batch: 0/45, Loss: 9.0282, Throughput: 80.49 samples/sec
2025-03-26 03:33:20,828 - training - INFO - Memory: GPU 0: 3801.2MB allocated, 9188.0MB reserved
2025-03-26 03:33:20,828 - training - INFO - Epoch: 5/200000, Batch: 15/45, Loss: 8.7264, Throughput: 78.44 samples/sec
2025-03-26 03:33:31,349 - training - INFO - Memory: GPU 0: 3802.8MB allocated, 9188.0MB reserved
2025-03-26 03:33:31,349 - training - INFO - Epoch: 5/200000, Batch: 30/45, Loss: 8.5584, Throughput: 79.11 samples/sec
2025-03-26 03:33:41,309 - training - INFO - Epoch 5 completed in 31.91s. Average loss: 8.4204
2025-03-26 03:33:41,312 - training - INFO - Starting epoch 6/200000
2025-03-26 03:33:42,025 - training - INFO - Memory: GPU 0: 3800.0MB allocated, 9312.0MB reserved
2025-03-26 03:33:42,025 - training - INFO - Epoch: 6/200000, Batch: 0/45, Loss: 7.8931, Throughput: 78.84 samples/sec
2025-03-26 03:33:52,806 - training - INFO - Memory: GPU 0: 3797.1MB allocated, 9084.0MB reserved
2025-03-26 03:33:52,806 - training - INFO - Epoch: 6/200000, Batch: 15/45, Loss: 7.8904, Throughput: 77.97 samples/sec
2025-03-26 03:34:03,428 - training - INFO - Memory: GPU 0: 3795.3MB allocated, 9086.0MB reserved
2025-03-26 03:34:03,428 - training - INFO - Epoch: 6/200000, Batch: 30/45, Loss: 7.7673, Throughput: 78.50 samples/sec
2025-03-26 03:34:13,484 - training - INFO - Epoch 6 completed in 32.17s. Average loss: 7.7228
2025-03-26 03:34:13,487 - training - INFO - Starting epoch 7/200000
2025-03-26 03:34:14,177 - training - INFO - Memory: GPU 0: 3800.2MB allocated, 9210.0MB reserved
2025-03-26 03:34:14,178 - training - INFO - Epoch: 7/200000, Batch: 0/45, Loss: 7.2066, Throughput: 81.25 samples/sec
2025-03-26 03:34:25,001 - training - INFO - Memory: GPU 0: 3796.3MB allocated, 9062.0MB reserved
2025-03-26 03:34:25,001 - training - INFO - Epoch: 7/200000, Batch: 15/45, Loss: 7.4281, Throughput: 77.82 samples/sec
2025-03-26 03:34:35,547 - training - INFO - Memory: GPU 0: 3798.2MB allocated, 9062.0MB reserved
2025-03-26 03:34:35,547 - training - INFO - Epoch: 7/200000, Batch: 30/45, Loss: 7.3202, Throughput: 78.70 samples/sec
2025-03-26 03:34:45,545 - training - INFO - Epoch 7 completed in 32.06s. Average loss: 7.2520
2025-03-26 03:34:45,548 - training - INFO - Starting epoch 8/200000
2025-03-26 03:34:46,253 - training - INFO - Memory: GPU 0: 3800.5MB allocated, 9188.0MB reserved
2025-03-26 03:34:46,253 - training - INFO - Epoch: 8/200000, Batch: 0/45, Loss: 7.0694, Throughput: 79.64 samples/sec
2025-03-26 03:34:56,999 - training - INFO - Memory: GPU 0: 3797.6MB allocated, 9064.0MB reserved
2025-03-26 03:34:57,000 - training - INFO - Epoch: 8/200000, Batch: 15/45, Loss: 6.9963, Throughput: 78.26 samples/sec
2025-03-26 03:35:07,528 - training - INFO - Memory: GPU 0: 3802.7MB allocated, 9066.0MB reserved
2025-03-26 03:35:07,529 - training - INFO - Epoch: 8/200000, Batch: 30/45, Loss: 6.9492, Throughput: 78.98 samples/sec
2025-03-26 03:35:17,469 - training - INFO - Epoch 8 completed in 31.92s. Average loss: 6.8852
2025-03-26 03:35:17,472 - training - INFO - Starting epoch 9/200000
2025-03-26 03:35:18,161 - training - INFO - Memory: GPU 0: 3795.2MB allocated, 9192.0MB reserved
2025-03-26 03:35:18,161 - training - INFO - Epoch: 9/200000, Batch: 0/45, Loss: 6.6112, Throughput: 81.52 samples/sec
2025-03-26 03:35:29,104 - training - INFO - Memory: GPU 0: 3797.4MB allocated, 9064.0MB reserved
2025-03-26 03:35:29,105 - training - INFO - Epoch: 9/200000, Batch: 15/45, Loss: 6.6510, Throughput: 77.04 samples/sec
2025-03-26 03:35:39,797 - training - INFO - Memory: GPU 0: 3795.4MB allocated, 9066.0MB reserved
2025-03-26 03:35:39,798 - training - INFO - Epoch: 9/200000, Batch: 30/45, Loss: 6.6465, Throughput: 77.77 samples/sec
2025-03-26 03:35:49,834 - training - INFO - Epoch 9 completed in 32.36s. Average loss: 6.6191
2025-03-26 03:35:49,842 - training - INFO - Starting epoch 10/200000
2025-03-26 03:35:50,534 - training - INFO - Memory: GPU 0: 3792.2MB allocated, 9190.0MB reserved
2025-03-26 03:35:50,534 - training - INFO - Epoch: 10/200000, Batch: 0/45, Loss: 6.3320, Throughput: 81.05 samples/sec
2025-03-26 03:36:01,286 - training - INFO - Memory: GPU 0: 3797.7MB allocated, 9092.0MB reserved
2025-03-26 03:36:01,286 - training - INFO - Epoch: 10/200000, Batch: 15/45, Loss: 6.4582, Throughput: 78.31 samples/sec
2025-03-26 03:36:11,880 - training - INFO - Memory: GPU 0: 3794.0MB allocated, 9092.0MB reserved
2025-03-26 03:36:11,880 - training - INFO - Epoch: 10/200000, Batch: 30/45, Loss: 6.4535, Throughput: 78.78 samples/sec
2025-03-26 03:36:21,826 - training - INFO - Epoch 10 completed in 31.98s. Average loss: 6.4296
2025-03-26 03:36:21,830 - training - INFO - Starting validation...
2025-03-26 03:36:25,464 - training - INFO - Validation Loss: 9.9689
2025-03-26 03:36:25,466 - training - INFO - Validation loss improved significantly from inf to 9.9689
2025-03-26 03:43:09,771 - training - INFO - Training completed successfully.
2025-03-26 03:45:35,379 - training - INFO - Overriding batch size with command-line value: 7
2025-03-26 03:45:35,380 - training - INFO - Overriding gradient accumulation steps with command-line value: 3
2025-03-26 03:45:35,380 - training - INFO - Starting training with debugging enabled. Error file: /tmp/torch_elastic_error_apq150lw.log
2025-03-26 03:45:35,380 - training - INFO - Process information: Rank 0, Local Rank 0, World Size 8
2025-03-26 03:45:35,380 - training - INFO - Device: cuda:0
2025-03-26 03:45:35,889 - training - INFO - Training on 9 GPUs, distributed mode: True
2025-03-26 03:45:35,889 - training - INFO - Starting dataset preprocessing on rank 0...
2025-03-26 03:45:35,889 - training - INFO - Starting dataset preprocessing (this will run only once)...
2025-03-26 03:45:35,891 - training - INFO - Preprocessed data already exists at /app/datasets/processed_dataset.pkl. Skipping preprocessing.
2025-03-26 03:45:35,891 - training - INFO - Dataset preprocessing complete. Took 0.00 seconds.
2025-03-26 03:45:45,478 - training - INFO - Starting model initialization...
2025-03-26 03:45:55,916 - training - INFO - Dataset split: 2466 training, 137 validation, 137 test samples
2025-03-26 03:45:56,039 - training - INFO - Test dataset indices saved to /app/UAV-Language-Guided-Navigation/AnsweringAgent/outputs/logs/test_indices.pt
2025-03-26 03:45:56,039 - training - INFO - Per-GPU batch size: 7 (effective batch size: 168, with gradient_accumulation_steps=3)
2025-03-26 03:45:56,079 - training - INFO - Created 24 gradient buckets for efficient all-reduce
2025-03-26 03:45:56,083 - training - INFO - Starting epoch 1/200000
2025-03-26 03:45:58,012 - training - ERROR - Fatal error in main function: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 5; 10.75 GiB total capacity; 1.52 GiB already allocated; 3.81 MiB free; 1.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2025-03-26 03:45:58,012 - training - ERROR - Traceback (most recent call last):
  File "AnsweringAgent/src/train.py", line 825, in main
    train_model(
  File "AnsweringAgent/src/train.py", line 165, in train_model
    ema = EMA(model, decay=0.999)
  File "AnsweringAgent/src/train.py", line 60, in __init__
    self.shadow[name] = param.data.clone()
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 5; 10.75 GiB total capacity; 1.52 GiB already allocated; 3.81 MiB free; 1.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-03-26 03:45:58,208 - training - ERROR - Fatal error in main function: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 7; 10.75 GiB total capacity; 1.53 GiB already allocated; 1.81 MiB free; 1.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2025-03-26 03:45:58,208 - training - ERROR - Traceback (most recent call last):
  File "AnsweringAgent/src/train.py", line 825, in main
    train_model(
  File "AnsweringAgent/src/train.py", line 165, in train_model
    ema = EMA(model, decay=0.999)
  File "AnsweringAgent/src/train.py", line 60, in __init__
    self.shadow[name] = param.data.clone()
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 7; 10.75 GiB total capacity; 1.53 GiB already allocated; 1.81 MiB free; 1.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-03-26 03:45:58,229 - training - ERROR - Fatal error in main function: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 2; 10.75 GiB total capacity; 1.55 GiB already allocated; 1.81 MiB free; 1.59 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2025-03-26 03:45:58,229 - training - ERROR - Traceback (most recent call last):
  File "AnsweringAgent/src/train.py", line 825, in main
    train_model(
  File "AnsweringAgent/src/train.py", line 165, in train_model
    ema = EMA(model, decay=0.999)
  File "AnsweringAgent/src/train.py", line 60, in __init__
    self.shadow[name] = param.data.clone()
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 2; 10.75 GiB total capacity; 1.55 GiB already allocated; 1.81 MiB free; 1.59 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-03-26 03:45:58,290 - training - ERROR - Fatal error in main function: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 1; 10.75 GiB total capacity; 1.52 GiB already allocated; 3.81 MiB free; 1.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2025-03-26 03:45:58,291 - training - ERROR - Traceback (most recent call last):
  File "AnsweringAgent/src/train.py", line 825, in main
    train_model(
  File "AnsweringAgent/src/train.py", line 165, in train_model
    ema = EMA(model, decay=0.999)
  File "AnsweringAgent/src/train.py", line 60, in __init__
    self.shadow[name] = param.data.clone()
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 1; 10.75 GiB total capacity; 1.52 GiB already allocated; 3.81 MiB free; 1.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-03-26 03:45:58,303 - training - ERROR - Fatal error in main function: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 3; 10.75 GiB total capacity; 1.50 GiB already allocated; 17.81 MiB free; 1.54 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2025-03-26 03:45:58,303 - training - ERROR - Traceback (most recent call last):
  File "AnsweringAgent/src/train.py", line 825, in main
    train_model(
  File "AnsweringAgent/src/train.py", line 165, in train_model
    ema = EMA(model, decay=0.999)
  File "AnsweringAgent/src/train.py", line 60, in __init__
    self.shadow[name] = param.data.clone()
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 3; 10.75 GiB total capacity; 1.50 GiB already allocated; 17.81 MiB free; 1.54 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-03-26 03:45:58,418 - training - ERROR - Fatal error in main function: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 4; 10.75 GiB total capacity; 1.52 GiB already allocated; 11.81 MiB free; 1.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2025-03-26 03:45:58,419 - training - ERROR - Traceback (most recent call last):
  File "AnsweringAgent/src/train.py", line 825, in main
    train_model(
  File "AnsweringAgent/src/train.py", line 165, in train_model
    ema = EMA(model, decay=0.999)
  File "AnsweringAgent/src/train.py", line 60, in __init__
    self.shadow[name] = param.data.clone()
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 4; 10.75 GiB total capacity; 1.52 GiB already allocated; 11.81 MiB free; 1.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-03-26 03:45:58,505 - training - ERROR - Fatal error in main function: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 6; 10.75 GiB total capacity; 1.53 GiB already allocated; 17.81 MiB free; 1.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
2025-03-26 03:45:58,505 - training - ERROR - Traceback (most recent call last):
  File "AnsweringAgent/src/train.py", line 825, in main
    train_model(
  File "AnsweringAgent/src/train.py", line 165, in train_model
    ema = EMA(model, decay=0.999)
  File "AnsweringAgent/src/train.py", line 60, in __init__
    self.shadow[name] = param.data.clone()
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 6; 10.75 GiB total capacity; 1.53 GiB already allocated; 17.81 MiB free; 1.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

2025-03-26 03:53:23,506 - training - INFO - Overriding batch size with command-line value: 7
2025-03-26 03:53:23,506 - training - INFO - Overriding gradient accumulation steps with command-line value: 3
2025-03-26 03:53:23,506 - training - INFO - Starting training with debugging enabled. Error file: /tmp/torch_elastic_error_infq6uof.log
2025-03-26 03:53:23,506 - training - INFO - Process information: Rank 0, Local Rank 0, World Size 8
2025-03-26 03:53:23,507 - training - INFO - Device: cuda:0
2025-03-26 03:53:24,311 - training - INFO - Training on 8 GPUs, distributed mode: True
2025-03-26 03:53:24,311 - training - INFO - Starting dataset preprocessing on rank 0...
2025-03-26 03:53:24,311 - training - INFO - Starting dataset preprocessing (this will run only once)...
2025-03-26 03:53:24,313 - training - INFO - Preprocessed data already exists at /app/datasets/processed_dataset.pkl. Skipping preprocessing.
2025-03-26 03:53:24,313 - training - INFO - Dataset preprocessing complete. Took 0.00 seconds.
2025-03-26 03:53:29,034 - training - INFO - Starting model initialization...
2025-03-26 03:53:54,260 - training - INFO - Dataset split: 2466 training, 137 validation, 137 test samples
2025-03-26 03:53:54,423 - training - INFO - Test dataset indices saved to /app/UAV-Language-Guided-Navigation/AnsweringAgent/outputs/logs/test_indices.pt
2025-03-26 03:53:54,424 - training - INFO - Per-GPU batch size: 7 (effective batch size: 168, with gradient_accumulation_steps=3)
2025-03-26 03:53:54,462 - training - INFO - Created 24 gradient buckets for efficient all-reduce
2025-03-26 03:53:54,466 - training - INFO - Starting epoch 1/200000
2025-03-26 03:54:01,276 - training - INFO - Memory: GPU 0: 2622.1MB allocated, 6558.0MB reserved
2025-03-26 03:54:01,279 - training - INFO - Epoch: 1/200000, Batch: 0/45, Loss: 11.0805, Throughput: 8.23 samples/sec
2025-03-26 03:54:11,939 - training - INFO - Memory: GPU 0: 3797.7MB allocated, 9100.0MB reserved
2025-03-26 03:54:11,940 - training - INFO - Epoch: 1/200000, Batch: 15/45, Loss: 11.1900, Throughput: 51.29 samples/sec
2025-03-26 03:54:22,482 - training - INFO - Memory: GPU 0: 3799.4MB allocated, 9100.0MB reserved
2025-03-26 03:54:22,484 - training - INFO - Epoch: 1/200000, Batch: 30/45, Loss: 11.1820, Throughput: 61.97 samples/sec
2025-03-26 03:54:33,717 - training - INFO - Epoch 1 completed in 39.25s. Average loss: 11.1788
2025-03-26 03:54:33,721 - training - INFO - Starting epoch 2/200000
2025-03-26 03:54:34,460 - training - INFO - Memory: GPU 0: 3802.1MB allocated, 8966.0MB reserved
2025-03-26 03:54:34,460 - training - INFO - Epoch: 2/200000, Batch: 0/45, Loss: 11.1819, Throughput: 75.94 samples/sec
2025-03-26 03:54:45,298 - training - INFO - Memory: GPU 0: 3802.0MB allocated, 9082.0MB reserved
2025-03-26 03:54:45,298 - training - INFO - Epoch: 2/200000, Batch: 15/45, Loss: 11.0016, Throughput: 77.41 samples/sec
2025-03-26 03:54:55,921 - training - INFO - Memory: GPU 0: 3798.7MB allocated, 9082.0MB reserved
2025-03-26 03:54:55,922 - training - INFO - Epoch: 2/200000, Batch: 30/45, Loss: 10.9143, Throughput: 78.20 samples/sec
2025-03-26 03:55:05,839 - training - INFO - Epoch 2 completed in 32.12s. Average loss: 10.8584
2025-03-26 03:55:05,842 - training - INFO - Starting epoch 3/200000
2025-03-26 03:55:06,547 - training - INFO - Memory: GPU 0: 3804.3MB allocated, 9208.0MB reserved
2025-03-26 03:55:06,547 - training - INFO - Epoch: 3/200000, Batch: 0/45, Loss: 10.3585, Throughput: 79.58 samples/sec
2025-03-26 03:55:17,391 - training - INFO - Memory: GPU 0: 3805.8MB allocated, 9182.0MB reserved
2025-03-26 03:55:17,391 - training - INFO - Epoch: 3/200000, Batch: 15/45, Loss: 10.4138, Throughput: 77.59 samples/sec
2025-03-26 03:55:27,953 - training - INFO - Memory: GPU 0: 3804.6MB allocated, 9182.0MB reserved
2025-03-26 03:55:27,953 - training - INFO - Epoch: 3/200000, Batch: 30/45, Loss: 10.2955, Throughput: 78.52 samples/sec
2025-03-26 03:55:37,880 - training - INFO - Epoch 3 completed in 32.04s. Average loss: 10.1961
2025-03-26 03:55:37,884 - training - INFO - Starting epoch 4/200000
2025-03-26 03:55:38,600 - training - INFO - Memory: GPU 0: 3810.4MB allocated, 9306.0MB reserved
2025-03-26 03:55:38,600 - training - INFO - Epoch: 4/200000, Batch: 0/45, Loss: 9.7623, Throughput: 78.41 samples/sec
2025-03-26 03:55:49,393 - training - INFO - Memory: GPU 0: 3806.3MB allocated, 9080.0MB reserved
2025-03-26 03:55:49,393 - training - INFO - Epoch: 4/200000, Batch: 15/45, Loss: 9.6333, Throughput: 77.87 samples/sec
2025-03-26 03:55:59,991 - training - INFO - Memory: GPU 0: 3801.1MB allocated, 9080.0MB reserved
2025-03-26 03:55:59,992 - training - INFO - Epoch: 4/200000, Batch: 30/45, Loss: 9.4865, Throughput: 78.53 samples/sec
2025-03-26 03:56:10,042 - training - INFO - Epoch 4 completed in 32.16s. Average loss: 9.3318
2025-03-26 03:56:10,045 - training - INFO - Starting epoch 5/200000
2025-03-26 03:56:10,727 - training - INFO - Memory: GPU 0: 3801.3MB allocated, 9204.0MB reserved
2025-03-26 03:56:10,727 - training - INFO - Epoch: 5/200000, Batch: 0/45, Loss: 9.0286, Throughput: 82.23 samples/sec
2025-03-26 03:56:21,604 - training - INFO - Memory: GPU 0: 3799.3MB allocated, 9184.0MB reserved
2025-03-26 03:56:21,606 - training - INFO - Epoch: 5/200000, Batch: 15/45, Loss: 8.7260, Throughput: 77.53 samples/sec
2025-03-26 03:56:32,184 - training - INFO - Memory: GPU 0: 3802.3MB allocated, 9184.0MB reserved
2025-03-26 03:56:32,184 - training - INFO - Epoch: 5/200000, Batch: 30/45, Loss: 8.5579, Throughput: 78.42 samples/sec
2025-03-26 03:56:42,103 - training - INFO - Epoch 5 completed in 32.06s. Average loss: 8.4200
2025-03-26 03:56:42,106 - training - INFO - Starting epoch 6/200000
2025-03-26 03:56:42,822 - training - INFO - Memory: GPU 0: 3804.2MB allocated, 9310.0MB reserved
2025-03-26 03:56:42,822 - training - INFO - Epoch: 6/200000, Batch: 0/45, Loss: 7.8934, Throughput: 78.37 samples/sec
2025-03-26 03:56:53,703 - training - INFO - Memory: GPU 0: 3797.1MB allocated, 9068.0MB reserved
2025-03-26 03:56:53,704 - training - INFO - Epoch: 6/200000, Batch: 15/45, Loss: 7.8903, Throughput: 77.27 samples/sec
2025-03-26 03:57:04,297 - training - INFO - Memory: GPU 0: 3800.1MB allocated, 9068.0MB reserved
2025-03-26 03:57:04,297 - training - INFO - Epoch: 6/200000, Batch: 30/45, Loss: 7.7672, Throughput: 78.24 samples/sec
2025-03-26 03:57:14,247 - training - INFO - Epoch 6 completed in 32.14s. Average loss: 7.7225
2025-03-26 03:57:14,250 - training - INFO - Starting epoch 7/200000
2025-03-26 03:57:14,935 - training - INFO - Memory: GPU 0: 3800.6MB allocated, 9192.0MB reserved
2025-03-26 03:57:14,936 - training - INFO - Epoch: 7/200000, Batch: 0/45, Loss: 7.2066, Throughput: 81.83 samples/sec
2025-03-26 03:57:25,740 - training - INFO - Memory: GPU 0: 3799.6MB allocated, 9072.0MB reserved
2025-03-26 03:57:25,741 - training - INFO - Epoch: 7/200000, Batch: 15/45, Loss: 7.4279, Throughput: 77.98 samples/sec
2025-03-26 03:57:36,337 - training - INFO - Memory: GPU 0: 3801.5MB allocated, 9074.0MB reserved
2025-03-26 03:57:36,337 - training - INFO - Epoch: 7/200000, Batch: 30/45, Loss: 7.3200, Throughput: 78.60 samples/sec
2025-03-26 03:57:46,245 - training - INFO - Epoch 7 completed in 31.99s. Average loss: 7.2519
2025-03-26 03:57:46,248 - training - INFO - Starting epoch 8/200000
2025-03-26 03:57:46,952 - training - INFO - Memory: GPU 0: 3800.2MB allocated, 9198.0MB reserved
2025-03-26 03:57:46,952 - training - INFO - Epoch: 8/200000, Batch: 0/45, Loss: 7.0688, Throughput: 79.64 samples/sec
2025-03-26 03:57:57,849 - training - INFO - Memory: GPU 0: 3797.2MB allocated, 9074.0MB reserved
2025-03-26 03:57:57,849 - training - INFO - Epoch: 8/200000, Batch: 15/45, Loss: 6.9962, Throughput: 77.24 samples/sec
2025-03-26 03:58:08,521 - training - INFO - Memory: GPU 0: 3798.5MB allocated, 9074.0MB reserved
2025-03-26 03:58:08,521 - training - INFO - Epoch: 8/200000, Batch: 30/45, Loss: 6.9490, Throughput: 77.94 samples/sec
2025-03-26 03:58:18,603 - training - INFO - Epoch 8 completed in 32.35s. Average loss: 6.8851
2025-03-26 03:58:18,606 - training - INFO - Starting epoch 9/200000
2025-03-26 03:58:19,306 - training - INFO - Memory: GPU 0: 3799.9MB allocated, 9200.0MB reserved
2025-03-26 03:58:19,307 - training - INFO - Epoch: 9/200000, Batch: 0/45, Loss: 6.6110, Throughput: 80.17 samples/sec
2025-03-26 03:58:30,156 - training - INFO - Memory: GPU 0: 3796.9MB allocated, 9092.0MB reserved
2025-03-26 03:58:30,156 - training - INFO - Epoch: 9/200000, Batch: 15/45, Loss: 6.6508, Throughput: 77.59 samples/sec
2025-03-26 03:58:40,770 - training - INFO - Memory: GPU 0: 3797.3MB allocated, 9092.0MB reserved
2025-03-26 03:58:40,770 - training - INFO - Epoch: 9/200000, Batch: 30/45, Loss: 6.6462, Throughput: 78.33 samples/sec
2025-03-26 03:58:50,694 - training - INFO - Epoch 9 completed in 32.09s. Average loss: 6.6190
2025-03-26 03:58:50,697 - training - INFO - Starting epoch 10/200000
2025-03-26 03:58:51,405 - training - INFO - Memory: GPU 0: 3797.4MB allocated, 9214.0MB reserved
2025-03-26 03:58:51,405 - training - INFO - Epoch: 10/200000, Batch: 0/45, Loss: 6.3311, Throughput: 79.31 samples/sec
2025-03-26 03:59:02,335 - training - INFO - Memory: GPU 0: 3793.7MB allocated, 9078.0MB reserved
2025-03-26 03:59:02,335 - training - INFO - Epoch: 10/200000, Batch: 15/45, Loss: 6.4581, Throughput: 77.00 samples/sec
2025-03-26 03:59:13,013 - training - INFO - Memory: GPU 0: 3799.1MB allocated, 9078.0MB reserved
2025-03-26 03:59:13,014 - training - INFO - Epoch: 10/200000, Batch: 30/45, Loss: 6.4534, Throughput: 77.80 samples/sec
2025-03-26 03:59:22,975 - training - INFO - Epoch 10 completed in 32.28s. Average loss: 6.4296
2025-03-26 03:59:22,979 - training - INFO - Starting validation...
2025-03-26 03:59:26,434 - training - INFO - Validation Loss: 9.9683
2025-03-26 03:59:26,434 - training - INFO - Validation loss improved significantly from inf to 9.9683
2025-03-26 03:59:26,464 - training - INFO - Starting epoch 11/200000
2025-03-26 03:59:27,223 - training - INFO - Memory: GPU 0: 3813.7MB allocated, 8446.0MB reserved
2025-03-26 03:59:27,223 - training - INFO - Epoch: 11/200000, Batch: 0/45, Loss: 6.5247, Throughput: 73.90 samples/sec
2025-03-26 03:59:37,906 - training - INFO - Memory: GPU 0: 3812.2MB allocated, 9048.0MB reserved
2025-03-26 03:59:37,906 - training - INFO - Epoch: 11/200000, Batch: 15/45, Loss: 6.3422, Throughput: 78.31 samples/sec
2025-03-26 03:59:48,482 - training - INFO - Memory: GPU 0: 3812.1MB allocated, 9048.0MB reserved
2025-03-26 03:59:48,483 - training - INFO - Epoch: 11/200000, Batch: 30/45, Loss: 6.3366, Throughput: 78.85 samples/sec
2025-03-26 03:59:58,462 - training - INFO - Epoch 11 completed in 32.00s. Average loss: 6.2854
2025-03-26 03:59:58,465 - training - INFO - Starting epoch 12/200000
2025-03-26 03:59:59,153 - training - INFO - Memory: GPU 0: 3808.8MB allocated, 9174.0MB reserved
2025-03-26 03:59:59,153 - training - INFO - Epoch: 12/200000, Batch: 0/45, Loss: 6.3137, Throughput: 81.61 samples/sec
2025-03-26 04:00:10,135 - training - INFO - Memory: GPU 0: 3810.0MB allocated, 9064.0MB reserved
2025-03-26 04:00:10,136 - training - INFO - Epoch: 12/200000, Batch: 15/45, Loss: 6.2791, Throughput: 76.79 samples/sec
2025-03-26 04:00:20,875 - training - INFO - Memory: GPU 0: 3811.4MB allocated, 9064.0MB reserved
2025-03-26 04:00:20,875 - training - INFO - Epoch: 12/200000, Batch: 30/45, Loss: 6.2362, Throughput: 77.47 samples/sec
2025-03-26 04:00:30,947 - training - INFO - Epoch 12 completed in 32.48s. Average loss: 6.1850
2025-03-26 04:00:30,951 - training - INFO - Starting epoch 13/200000
2025-03-26 04:00:31,638 - training - INFO - Memory: GPU 0: 3809.2MB allocated, 9190.0MB reserved
2025-03-26 04:00:31,638 - training - INFO - Epoch: 13/200000, Batch: 0/45, Loss: 6.4162, Throughput: 81.72 samples/sec
2025-03-26 04:00:42,483 - training - INFO - Memory: GPU 0: 3814.4MB allocated, 9082.0MB reserved
2025-03-26 04:00:42,483 - training - INFO - Epoch: 13/200000, Batch: 15/45, Loss: 6.1813, Throughput: 77.72 samples/sec
2025-03-26 04:00:53,044 - training - INFO - Memory: GPU 0: 3811.4MB allocated, 9082.0MB reserved
2025-03-26 04:00:53,045 - training - INFO - Epoch: 13/200000, Batch: 30/45, Loss: 6.1244, Throughput: 78.58 samples/sec
2025-03-26 04:01:02,951 - training - INFO - Epoch 13 completed in 32.00s. Average loss: 6.0997
2025-03-26 04:01:02,955 - training - INFO - Starting epoch 14/200000
2025-03-26 04:01:03,641 - training - INFO - Memory: GPU 0: 3810.9MB allocated, 9206.0MB reserved
2025-03-26 04:01:03,641 - training - INFO - Epoch: 14/200000, Batch: 0/45, Loss: 6.0127, Throughput: 81.89 samples/sec
2025-03-26 04:01:14,420 - training - INFO - Memory: GPU 0: 3814.1MB allocated, 9076.0MB reserved
2025-03-26 04:01:14,421 - training - INFO - Epoch: 14/200000, Batch: 15/45, Loss: 6.0300, Throughput: 78.17 samples/sec
2025-03-26 04:01:25,097 - training - INFO - Memory: GPU 0: 3813.5MB allocated, 9076.0MB reserved
2025-03-26 04:01:25,097 - training - INFO - Epoch: 14/200000, Batch: 30/45, Loss: 6.0089, Throughput: 78.41 samples/sec
2025-03-26 04:01:35,085 - training - INFO - Epoch 14 completed in 32.13s. Average loss: 6.0287
2025-03-26 04:01:35,088 - training - INFO - Starting epoch 15/200000
2025-03-26 04:01:35,801 - training - INFO - Memory: GPU 0: 3815.9MB allocated, 9202.0MB reserved
2025-03-26 04:01:35,802 - training - INFO - Epoch: 15/200000, Batch: 0/45, Loss: 6.4444, Throughput: 78.71 samples/sec
2025-03-26 04:01:46,666 - training - INFO - Memory: GPU 0: 3816.1MB allocated, 9078.0MB reserved
2025-03-26 04:01:46,666 - training - INFO - Epoch: 15/200000, Batch: 15/45, Loss: 6.0052, Throughput: 77.40 samples/sec
2025-03-26 04:01:57,354 - training - INFO - Memory: GPU 0: 3814.4MB allocated, 9078.0MB reserved
2025-03-26 04:01:57,354 - training - INFO - Epoch: 15/200000, Batch: 30/45, Loss: 5.9970, Throughput: 77.97 samples/sec
2025-03-26 04:02:07,315 - training - INFO - Epoch 15 completed in 32.23s. Average loss: 5.9714
2025-03-26 04:02:07,319 - training - INFO - Starting epoch 16/200000
2025-03-26 04:02:08,033 - training - INFO - Memory: GPU 0: 3813.4MB allocated, 9204.0MB reserved
2025-03-26 04:02:08,033 - training - INFO - Epoch: 16/200000, Batch: 0/45, Loss: 6.0215, Throughput: 78.64 samples/sec
2025-03-26 04:02:18,875 - training - INFO - Memory: GPU 0: 3814.0MB allocated, 9078.0MB reserved
2025-03-26 04:02:18,875 - training - INFO - Epoch: 16/200000, Batch: 15/45, Loss: 5.9337, Throughput: 77.54 samples/sec
2025-03-26 04:02:29,463 - training - INFO - Memory: GPU 0: 3813.5MB allocated, 9078.0MB reserved
2025-03-26 04:02:29,463 - training - INFO - Epoch: 16/200000, Batch: 30/45, Loss: 5.9123, Throughput: 78.40 samples/sec
2025-03-26 04:02:39,498 - training - INFO - Epoch 16 completed in 32.18s. Average loss: 5.9198
2025-03-26 04:02:39,502 - training - INFO - Starting epoch 17/200000
2025-03-26 04:02:40,184 - training - INFO - Memory: GPU 0: 3811.2MB allocated, 9204.0MB reserved
2025-03-26 04:02:40,184 - training - INFO - Epoch: 17/200000, Batch: 0/45, Loss: 5.9601, Throughput: 82.16 samples/sec
2025-03-26 04:02:51,010 - training - INFO - Memory: GPU 0: 3812.5MB allocated, 9068.0MB reserved
2025-03-26 04:02:51,010 - training - INFO - Epoch: 17/200000, Batch: 15/45, Loss: 5.8759, Throughput: 77.86 samples/sec
2025-03-26 04:03:01,572 - training - INFO - Memory: GPU 0: 3812.9MB allocated, 9068.0MB reserved
2025-03-26 04:03:01,572 - training - INFO - Epoch: 17/200000, Batch: 30/45, Loss: 5.8879, Throughput: 78.66 samples/sec
2025-03-26 04:03:11,566 - training - INFO - Epoch 17 completed in 32.06s. Average loss: 5.8733
2025-03-26 04:03:11,569 - training - INFO - Starting epoch 18/200000
2025-03-26 04:03:12,261 - training - INFO - Memory: GPU 0: 3811.6MB allocated, 9192.0MB reserved
2025-03-26 04:03:12,262 - training - INFO - Epoch: 18/200000, Batch: 0/45, Loss: 6.0793, Throughput: 81.11 samples/sec
2025-03-26 04:03:23,099 - training - INFO - Memory: GPU 0: 3815.3MB allocated, 9078.0MB reserved
2025-03-26 04:03:23,099 - training - INFO - Epoch: 18/200000, Batch: 15/45, Loss: 5.8796, Throughput: 77.72 samples/sec
2025-03-26 04:03:33,659 - training - INFO - Memory: GPU 0: 3814.7MB allocated, 9078.0MB reserved
2025-03-26 04:03:33,659 - training - INFO - Epoch: 18/200000, Batch: 30/45, Loss: 5.8704, Throughput: 78.60 samples/sec
2025-03-26 04:03:43,636 - training - INFO - Epoch 18 completed in 32.07s. Average loss: 5.8417
2025-03-26 04:03:43,639 - training - INFO - Starting epoch 19/200000
2025-03-26 04:03:44,336 - training - INFO - Memory: GPU 0: 3815.6MB allocated, 9204.0MB reserved
2025-03-26 04:03:44,336 - training - INFO - Epoch: 19/200000, Batch: 0/45, Loss: 5.7424, Throughput: 80.56 samples/sec
2025-03-26 04:03:55,176 - training - INFO - Memory: GPU 0: 3811.4MB allocated, 9068.0MB reserved
2025-03-26 04:03:55,176 - training - INFO - Epoch: 19/200000, Batch: 15/45, Loss: 5.8661, Throughput: 77.67 samples/sec
2025-03-26 04:04:05,726 - training - INFO - Memory: GPU 0: 3811.2MB allocated, 9068.0MB reserved
2025-03-26 04:04:05,726 - training - INFO - Epoch: 19/200000, Batch: 30/45, Loss: 5.8198, Throughput: 78.60 samples/sec
2025-03-26 04:04:15,634 - training - INFO - Epoch 19 completed in 32.00s. Average loss: 5.8108
2025-03-26 04:04:15,637 - training - INFO - Starting epoch 20/200000
2025-03-26 04:04:16,341 - training - INFO - Memory: GPU 0: 3813.4MB allocated, 9192.0MB reserved
2025-03-26 04:04:16,342 - training - INFO - Epoch: 20/200000, Batch: 0/45, Loss: 6.1260, Throughput: 79.63 samples/sec
2025-03-26 04:04:27,141 - training - INFO - Memory: GPU 0: 3810.8MB allocated, 9096.0MB reserved
2025-03-26 04:04:27,142 - training - INFO - Epoch: 20/200000, Batch: 15/45, Loss: 5.8027, Throughput: 77.90 samples/sec
2025-03-26 04:04:37,891 - training - INFO - Memory: GPU 0: 3813.6MB allocated, 9096.0MB reserved
2025-03-26 04:04:37,891 - training - INFO - Epoch: 20/200000, Batch: 30/45, Loss: 5.8049, Throughput: 78.01 samples/sec
2025-03-26 04:04:47,961 - training - INFO - Epoch 20 completed in 32.32s. Average loss: 5.7836
2025-03-26 04:04:47,964 - training - INFO - Starting validation...
2025-03-26 04:04:48,301 - training - INFO - Validation Loss: 7.6796
2025-03-26 04:04:48,301 - training - INFO - Validation loss improved significantly from 9.9683 to 7.6796
2025-03-26 04:04:48,524 - training - INFO - Starting epoch 21/200000
2025-03-26 04:04:49,251 - training - INFO - Memory: GPU 0: 3819.7MB allocated, 8562.0MB reserved
2025-03-26 04:04:49,251 - training - INFO - Epoch: 21/200000, Batch: 0/45, Loss: 5.6516, Throughput: 77.26 samples/sec
2025-03-26 04:04:59,957 - training - INFO - Memory: GPU 0: 3821.4MB allocated, 9062.0MB reserved
2025-03-26 04:04:59,957 - training - INFO - Epoch: 21/200000, Batch: 15/45, Loss: 5.8372, Throughput: 78.38 samples/sec
2025-03-26 04:05:10,662 - training - INFO - Memory: GPU 0: 3817.4MB allocated, 9062.0MB reserved
2025-03-26 04:05:10,663 - training - INFO - Epoch: 21/200000, Batch: 30/45, Loss: 5.7994, Throughput: 78.42 samples/sec
2025-03-26 04:05:20,723 - training - INFO - Epoch 21 completed in 32.20s. Average loss: 5.7409
2025-03-26 04:05:20,727 - training - INFO - Starting epoch 22/200000
2025-03-26 04:05:21,413 - training - INFO - Memory: GPU 0: 3811.2MB allocated, 9188.0MB reserved
2025-03-26 04:05:21,414 - training - INFO - Epoch: 22/200000, Batch: 0/45, Loss: 5.6789, Throughput: 81.62 samples/sec
2025-03-26 04:05:32,218 - training - INFO - Memory: GPU 0: 3815.8MB allocated, 9082.0MB reserved
2025-03-26 04:05:32,218 - training - INFO - Epoch: 22/200000, Batch: 15/45, Loss: 5.7184, Throughput: 77.98 samples/sec
2025-03-26 04:05:42,792 - training - INFO - Memory: GPU 0: 3814.9MB allocated, 9082.0MB reserved
2025-03-26 04:05:42,792 - training - INFO - Epoch: 22/200000, Batch: 30/45, Loss: 5.7365, Throughput: 78.68 samples/sec
2025-03-26 04:05:52,788 - training - INFO - Epoch 22 completed in 32.06s. Average loss: 5.7191
2025-03-26 04:05:52,791 - training - INFO - Starting epoch 23/200000
2025-03-26 04:05:53,500 - training - INFO - Memory: GPU 0: 3814.7MB allocated, 9206.0MB reserved
2025-03-26 04:05:53,501 - training - INFO - Epoch: 23/200000, Batch: 0/45, Loss: 5.8741, Throughput: 79.08 samples/sec
2025-03-26 04:06:04,338 - training - INFO - Memory: GPU 0: 3816.9MB allocated, 9072.0MB reserved
2025-03-26 04:06:04,339 - training - INFO - Epoch: 23/200000, Batch: 15/45, Loss: 5.7239, Throughput: 77.61 samples/sec
2025-03-26 04:06:14,966 - training - INFO - Memory: GPU 0: 3815.4MB allocated, 9072.0MB reserved
2025-03-26 04:06:14,966 - training - INFO - Epoch: 23/200000, Batch: 30/45, Loss: 5.7261, Throughput: 78.29 samples/sec
2025-03-26 04:06:25,015 - training - INFO - Epoch 23 completed in 32.22s. Average loss: 5.6982
2025-03-26 04:06:25,019 - training - INFO - Starting epoch 24/200000
2025-03-26 04:06:25,711 - training - INFO - Memory: GPU 0: 3817.4MB allocated, 9198.0MB reserved
2025-03-26 04:06:25,711 - training - INFO - Epoch: 24/200000, Batch: 0/45, Loss: 5.8289, Throughput: 80.94 samples/sec
2025-03-26 04:06:36,537 - training - INFO - Memory: GPU 0: 3817.9MB allocated, 9066.0MB reserved
2025-03-26 04:06:36,537 - training - INFO - Epoch: 24/200000, Batch: 15/45, Loss: 5.6659, Throughput: 77.80 samples/sec
2025-03-26 04:06:47,127 - training - INFO - Memory: GPU 0: 3819.9MB allocated, 9066.0MB reserved
2025-03-26 04:06:47,127 - training - INFO - Epoch: 24/200000, Batch: 30/45, Loss: 5.6522, Throughput: 78.52 samples/sec
2025-03-26 04:06:57,067 - training - INFO - Epoch 24 completed in 32.05s. Average loss: 5.6850
2025-03-26 04:06:57,071 - training - INFO - Starting epoch 25/200000
2025-03-26 04:06:57,761 - training - INFO - Memory: GPU 0: 3818.3MB allocated, 9190.0MB reserved
2025-03-26 04:06:57,761 - training - INFO - Epoch: 25/200000, Batch: 0/45, Loss: 5.5810, Throughput: 81.30 samples/sec
2025-03-26 04:07:08,716 - training - INFO - Memory: GPU 0: 3816.2MB allocated, 9082.0MB reserved
2025-03-26 04:07:08,716 - training - INFO - Epoch: 25/200000, Batch: 15/45, Loss: 5.7072, Throughput: 76.95 samples/sec
2025-03-26 04:07:19,372 - training - INFO - Memory: GPU 0: 3816.5MB allocated, 9082.0MB reserved
2025-03-26 04:07:19,372 - training - INFO - Epoch: 25/200000, Batch: 30/45, Loss: 5.6382, Throughput: 77.85 samples/sec
2025-03-26 04:07:29,356 - training - INFO - Epoch 25 completed in 32.29s. Average loss: 5.6565
2025-03-26 04:07:29,359 - training - INFO - Starting epoch 26/200000
2025-03-26 04:07:30,057 - training - INFO - Memory: GPU 0: 3818.6MB allocated, 9208.0MB reserved
2025-03-26 04:07:30,057 - training - INFO - Epoch: 26/200000, Batch: 0/45, Loss: 6.0225, Throughput: 80.48 samples/sec
2025-03-26 04:07:40,815 - training - INFO - Memory: GPU 0: 3818.8MB allocated, 9088.0MB reserved
2025-03-26 04:07:40,816 - training - INFO - Epoch: 26/200000, Batch: 15/45, Loss: 5.6080, Throughput: 78.22 samples/sec
2025-03-26 04:07:51,339 - training - INFO - Memory: GPU 0: 3818.4MB allocated, 9088.0MB reserved
2025-03-26 04:07:51,340 - training - INFO - Epoch: 26/200000, Batch: 30/45, Loss: 5.6370, Throughput: 78.99 samples/sec
2025-03-26 04:08:01,302 - training - INFO - Epoch 26 completed in 31.94s. Average loss: 5.6372
2025-03-26 04:08:01,305 - training - INFO - Starting epoch 27/200000
2025-03-26 04:08:02,018 - training - INFO - Memory: GPU 0: 3819.7MB allocated, 9214.0MB reserved
2025-03-26 04:08:02,018 - training - INFO - Epoch: 27/200000, Batch: 0/45, Loss: 5.7698, Throughput: 78.74 samples/sec
2025-03-26 04:08:12,931 - training - INFO - Memory: GPU 0: 3816.7MB allocated, 9056.0MB reserved
2025-03-26 04:08:12,931 - training - INFO - Epoch: 27/200000, Batch: 15/45, Loss: 5.6378, Throughput: 77.08 samples/sec
2025-03-26 04:08:23,531 - training - INFO - Memory: GPU 0: 3812.0MB allocated, 9056.0MB reserved
2025-03-26 04:08:23,532 - training - INFO - Epoch: 27/200000, Batch: 30/45, Loss: 5.6251, Throughput: 78.11 samples/sec
2025-03-26 04:08:33,596 - training - INFO - Epoch 27 completed in 32.29s. Average loss: 5.6262
2025-03-26 04:08:33,599 - training - INFO - Starting epoch 28/200000
2025-03-26 04:08:34,288 - training - INFO - Memory: GPU 0: 3810.5MB allocated, 9182.0MB reserved
2025-03-26 04:08:34,289 - training - INFO - Epoch: 28/200000, Batch: 0/45, Loss: 5.6779, Throughput: 81.50 samples/sec
2025-03-26 04:08:45,169 - training - INFO - Memory: GPU 0: 3810.1MB allocated, 9058.0MB reserved
2025-03-26 04:08:45,169 - training - INFO - Epoch: 28/200000, Batch: 15/45, Loss: 5.6537, Throughput: 77.45 samples/sec
2025-03-26 04:08:55,736 - training - INFO - Memory: GPU 0: 3814.3MB allocated, 9058.0MB reserved
2025-03-26 04:08:55,736 - training - INFO - Epoch: 28/200000, Batch: 30/45, Loss: 5.6343, Throughput: 78.43 samples/sec
2025-03-26 04:09:05,699 - training - INFO - Epoch 28 completed in 32.10s. Average loss: 5.6058
2025-03-26 04:09:05,702 - training - INFO - Starting epoch 29/200000
2025-03-26 04:09:06,416 - training - INFO - Memory: GPU 0: 3814.3MB allocated, 9184.0MB reserved
2025-03-26 04:09:06,417 - training - INFO - Epoch: 29/200000, Batch: 0/45, Loss: 5.6157, Throughput: 78.57 samples/sec
2025-03-26 04:09:17,263 - training - INFO - Memory: GPU 0: 3817.3MB allocated, 9088.0MB reserved
2025-03-26 04:09:17,263 - training - INFO - Epoch: 29/200000, Batch: 15/45, Loss: 5.5878, Throughput: 77.51 samples/sec
2025-03-26 04:09:27,794 - training - INFO - Memory: GPU 0: 3814.6MB allocated, 9088.0MB reserved
2025-03-26 04:09:27,794 - training - INFO - Epoch: 29/200000, Batch: 30/45, Loss: 5.5968, Throughput: 78.59 samples/sec
2025-03-26 04:09:37,718 - training - INFO - Epoch 29 completed in 32.02s. Average loss: 5.5912
2025-03-26 04:09:37,721 - training - INFO - Starting epoch 30/200000
2025-03-26 04:09:38,443 - training - INFO - Memory: GPU 0: 3819.0MB allocated, 9214.0MB reserved
2025-03-26 04:09:38,444 - training - INFO - Epoch: 30/200000, Batch: 0/45, Loss: 5.5283, Throughput: 77.70 samples/sec
2025-03-26 04:09:49,372 - training - INFO - Memory: GPU 0: 3816.1MB allocated, 9064.0MB reserved
2025-03-26 04:09:49,373 - training - INFO - Epoch: 30/200000, Batch: 15/45, Loss: 5.5616, Throughput: 76.92 samples/sec
2025-03-26 04:09:59,991 - training - INFO - Memory: GPU 0: 3814.2MB allocated, 9064.0MB reserved
2025-03-26 04:09:59,991 - training - INFO - Epoch: 30/200000, Batch: 30/45, Loss: 5.5789, Throughput: 77.96 samples/sec
2025-03-26 04:10:09,907 - training - INFO - Epoch 30 completed in 32.19s. Average loss: 5.5826
2025-03-26 04:10:09,910 - training - INFO - Starting validation...
2025-03-26 04:10:10,232 - training - INFO - Validation Loss: 6.5587
2025-03-26 04:10:10,232 - training - INFO - Validation loss improved significantly from 7.6796 to 6.5587
2025-03-26 04:10:10,466 - training - INFO - Starting epoch 31/200000
2025-03-26 04:10:11,174 - training - INFO - Memory: GPU 0: 3816.3MB allocated, 8500.0MB reserved
2025-03-26 04:10:11,175 - training - INFO - Epoch: 31/200000, Batch: 0/45, Loss: 5.4916, Throughput: 79.26 samples/sec
2025-03-26 04:10:21,920 - training - INFO - Memory: GPU 0: 3811.5MB allocated, 9052.0MB reserved
2025-03-26 04:10:21,920 - training - INFO - Epoch: 31/200000, Batch: 15/45, Loss: 5.6258, Throughput: 78.23 samples/sec
2025-03-26 04:10:32,549 - training - INFO - Memory: GPU 0: 3808.7MB allocated, 9052.0MB reserved
2025-03-26 04:10:32,549 - training - INFO - Epoch: 31/200000, Batch: 30/45, Loss: 5.5861, Throughput: 78.62 samples/sec
2025-03-26 04:10:42,579 - training - INFO - Epoch 31 completed in 32.11s. Average loss: 5.5708
2025-03-26 04:10:42,582 - training - INFO - Starting epoch 32/200000
2025-03-26 04:10:43,279 - training - INFO - Memory: GPU 0: 3810.9MB allocated, 9176.0MB reserved
2025-03-26 04:10:43,279 - training - INFO - Epoch: 32/200000, Batch: 0/45, Loss: 5.4379, Throughput: 80.58 samples/sec
2025-03-26 04:10:54,028 - training - INFO - Memory: GPU 0: 3813.1MB allocated, 9086.0MB reserved
2025-03-26 04:10:54,028 - training - INFO - Epoch: 32/200000, Batch: 15/45, Loss: 5.6070, Throughput: 78.29 samples/sec
2025-03-26 04:11:04,536 - training - INFO - Memory: GPU 0: 3814.3MB allocated, 9086.0MB reserved
2025-03-26 04:11:04,537 - training - INFO - Epoch: 32/200000, Batch: 30/45, Loss: 5.5627, Throughput: 79.08 samples/sec
2025-03-26 04:11:14,493 - training - INFO - Epoch 32 completed in 31.91s. Average loss: 5.5566
2025-03-26 04:11:14,497 - training - INFO - Starting epoch 33/200000
2025-03-26 04:11:15,190 - training - INFO - Memory: GPU 0: 3812.3MB allocated, 9210.0MB reserved
2025-03-26 04:11:15,190 - training - INFO - Epoch: 33/200000, Batch: 0/45, Loss: 5.7470, Throughput: 80.91 samples/sec
2025-03-26 04:11:26,014 - training - INFO - Memory: GPU 0: 3811.0MB allocated, 9102.0MB reserved
2025-03-26 04:11:26,014 - training - INFO - Epoch: 33/200000, Batch: 15/45, Loss: 5.5442, Throughput: 77.81 samples/sec
2025-03-26 04:11:36,583 - training - INFO - Memory: GPU 0: 3813.1MB allocated, 9102.0MB reserved
2025-03-26 04:11:36,583 - training - INFO - Epoch: 33/200000, Batch: 30/45, Loss: 5.5079, Throughput: 78.61 samples/sec
2025-03-26 04:11:46,530 - training - INFO - Epoch 33 completed in 32.03s. Average loss: 5.5522
2025-03-26 04:11:46,533 - training - INFO - Starting epoch 34/200000
2025-03-26 04:11:47,234 - training - INFO - Memory: GPU 0: 3814.2MB allocated, 9226.0MB reserved
2025-03-26 04:11:47,234 - training - INFO - Epoch: 34/200000, Batch: 0/45, Loss: 5.4609, Throughput: 80.12 samples/sec
2025-03-26 04:11:58,016 - training - INFO - Memory: GPU 0: 3814.5MB allocated, 9084.0MB reserved
2025-03-26 04:11:58,017 - training - INFO - Epoch: 34/200000, Batch: 15/45, Loss: 5.5686, Throughput: 78.04 samples/sec
2025-03-26 04:12:08,542 - training - INFO - Memory: GPU 0: 3814.2MB allocated, 9084.0MB reserved
2025-03-26 04:12:08,543 - training - INFO - Epoch: 34/200000, Batch: 30/45, Loss: 5.5773, Throughput: 78.89 samples/sec
2025-03-26 04:12:18,574 - training - INFO - Epoch 34 completed in 32.04s. Average loss: 5.5468
2025-03-26 04:12:18,578 - training - INFO - Starting epoch 35/200000
2025-03-26 04:12:19,272 - training - INFO - Memory: GPU 0: 3817.9MB allocated, 9208.0MB reserved
2025-03-26 04:12:19,273 - training - INFO - Epoch: 35/200000, Batch: 0/45, Loss: 5.6755, Throughput: 80.76 samples/sec
2025-03-26 04:12:30,134 - training - INFO - Memory: GPU 0: 3815.0MB allocated, 9078.0MB reserved
2025-03-26 04:12:30,134 - training - INFO - Epoch: 35/200000, Batch: 15/45, Loss: 5.4074, Throughput: 77.55 samples/sec
2025-03-26 04:12:40,678 - training - INFO - Memory: GPU 0: 3816.6MB allocated, 9078.0MB reserved
2025-03-26 04:12:40,678 - training - INFO - Epoch: 35/200000, Batch: 30/45, Loss: 5.4708, Throughput: 78.56 samples/sec
2025-03-26 04:12:50,567 - training - INFO - Epoch 35 completed in 31.99s. Average loss: 5.5439
2025-03-26 04:12:50,604 - training - INFO - Starting epoch 36/200000
2025-03-26 04:12:51,271 - training - INFO - Memory: GPU 0: 3817.5MB allocated, 9202.0MB reserved
2025-03-26 04:12:51,271 - training - INFO - Epoch: 36/200000, Batch: 0/45, Loss: 5.5322, Throughput: 84.20 samples/sec
2025-03-26 04:13:02,008 - training - INFO - Memory: GPU 0: 3818.9MB allocated, 9096.0MB reserved
2025-03-26 04:13:02,008 - training - INFO - Epoch: 36/200000, Batch: 15/45, Loss: 5.5283, Throughput: 78.58 samples/sec
2025-03-26 04:13:12,611 - training - INFO - Memory: GPU 0: 3816.3MB allocated, 9096.0MB reserved
2025-03-26 04:13:12,611 - training - INFO - Epoch: 36/200000, Batch: 30/45, Loss: 5.5393, Throughput: 78.89 samples/sec
2025-03-26 04:13:22,583 - training - INFO - Epoch 36 completed in 31.98s. Average loss: 5.5305
2025-03-26 04:13:22,587 - training - INFO - Starting epoch 37/200000
2025-03-26 04:13:23,278 - training - INFO - Memory: GPU 0: 3816.1MB allocated, 9222.0MB reserved
2025-03-26 04:13:23,278 - training - INFO - Epoch: 37/200000, Batch: 0/45, Loss: 5.2594, Throughput: 81.08 samples/sec
2025-03-26 04:13:34,192 - training - INFO - Memory: GPU 0: 3812.8MB allocated, 9078.0MB reserved
2025-03-26 04:13:34,192 - training - INFO - Epoch: 37/200000, Batch: 15/45, Loss: 5.5475, Throughput: 77.21 samples/sec
2025-03-26 04:13:44,738 - training - INFO - Memory: GPU 0: 3814.9MB allocated, 9078.0MB reserved
2025-03-26 04:13:44,738 - training - INFO - Epoch: 37/200000, Batch: 30/45, Loss: 5.5274, Throughput: 78.37 samples/sec
2025-03-26 04:13:54,763 - training - INFO - Epoch 37 completed in 32.18s. Average loss: 5.5273
2025-03-26 04:13:54,767 - training - INFO - Starting epoch 38/200000
2025-03-26 04:13:55,466 - training - INFO - Memory: GPU 0: 3814.4MB allocated, 9206.0MB reserved
2025-03-26 04:13:55,467 - training - INFO - Epoch: 38/200000, Batch: 0/45, Loss: 5.3675, Throughput: 80.30 samples/sec
2025-03-26 04:14:06,299 - training - INFO - Memory: GPU 0: 3817.7MB allocated, 9076.0MB reserved
2025-03-26 04:14:06,299 - training - INFO - Epoch: 38/200000, Batch: 15/45, Loss: 5.5378, Throughput: 77.71 samples/sec
2025-03-26 04:14:16,916 - training - INFO - Memory: GPU 0: 3814.5MB allocated, 9076.0MB reserved
2025-03-26 04:14:16,917 - training - INFO - Epoch: 38/200000, Batch: 30/45, Loss: 5.5321, Throughput: 78.38 samples/sec
2025-03-26 04:14:26,905 - training - INFO - Epoch 38 completed in 32.14s. Average loss: 5.5177
2025-03-26 04:14:26,908 - training - INFO - Starting epoch 39/200000
2025-03-26 04:14:27,602 - training - INFO - Memory: GPU 0: 3815.4MB allocated, 9202.0MB reserved
2025-03-26 04:14:27,602 - training - INFO - Epoch: 39/200000, Batch: 0/45, Loss: 5.5908, Throughput: 80.97 samples/sec
2025-03-26 04:14:38,418 - training - INFO - Memory: GPU 0: 3814.1MB allocated, 9090.0MB reserved
2025-03-26 04:14:38,418 - training - INFO - Epoch: 39/200000, Batch: 15/45, Loss: 5.5487, Throughput: 77.86 samples/sec
2025-03-26 04:14:49,012 - training - INFO - Memory: GPU 0: 3818.3MB allocated, 9090.0MB reserved
2025-03-26 04:14:49,013 - training - INFO - Epoch: 39/200000, Batch: 30/45, Loss: 5.5179, Throughput: 78.54 samples/sec
2025-03-26 04:14:58,931 - training - INFO - Epoch 39 completed in 32.02s. Average loss: 5.5061
2025-03-26 04:14:58,934 - training - INFO - Starting epoch 40/200000
2025-03-26 04:14:59,630 - training - INFO - Memory: GPU 0: 3814.1MB allocated, 9216.0MB reserved
2025-03-26 04:14:59,630 - training - INFO - Epoch: 40/200000, Batch: 0/45, Loss: 5.5368, Throughput: 80.62 samples/sec
2025-03-26 04:15:10,439 - training - INFO - Memory: GPU 0: 3815.7MB allocated, 9082.0MB reserved
2025-03-26 04:15:10,439 - training - INFO - Epoch: 40/200000, Batch: 15/45, Loss: 5.5217, Throughput: 77.89 samples/sec
2025-03-26 04:15:21,056 - training - INFO - Memory: GPU 0: 3816.5MB allocated, 9082.0MB reserved
2025-03-26 04:15:21,056 - training - INFO - Epoch: 40/200000, Batch: 30/45, Loss: 5.5307, Throughput: 78.48 samples/sec
2025-03-26 04:15:31,000 - training - INFO - Epoch 40 completed in 32.07s. Average loss: 5.5055
2025-03-26 04:15:31,003 - training - INFO - Starting validation...
2025-03-26 04:15:31,325 - training - INFO - Validation Loss: 6.3260
2025-03-26 04:15:31,326 - training - INFO - Validation loss improved significantly from 6.5587 to 6.3260
2025-03-26 04:15:31,558 - training - INFO - Starting epoch 41/200000
2025-03-26 04:15:32,277 - training - INFO - Memory: GPU 0: 3816.2MB allocated, 8474.0MB reserved
2025-03-26 04:15:32,277 - training - INFO - Epoch: 41/200000, Batch: 0/45, Loss: 5.5457, Throughput: 78.00 samples/sec
2025-03-26 04:15:42,997 - training - INFO - Memory: GPU 0: 3819.1MB allocated, 9064.0MB reserved
2025-03-26 04:15:42,998 - training - INFO - Epoch: 41/200000, Batch: 15/45, Loss: 5.4790, Throughput: 78.34 samples/sec
2025-03-26 04:15:53,515 - training - INFO - Memory: GPU 0: 3819.3MB allocated, 9064.0MB reserved
2025-03-26 04:15:53,516 - training - INFO - Epoch: 41/200000, Batch: 30/45, Loss: 5.4866, Throughput: 79.07 samples/sec
2025-03-26 04:16:03,440 - training - INFO - Epoch 41 completed in 31.88s. Average loss: 5.5045
2025-03-26 04:16:03,444 - training - INFO - Starting epoch 42/200000
2025-03-26 04:16:04,127 - training - INFO - Memory: GPU 0: 3815.4MB allocated, 9190.0MB reserved
2025-03-26 04:16:04,127 - training - INFO - Epoch: 42/200000, Batch: 0/45, Loss: 5.4213, Throughput: 82.16 samples/sec
2025-03-26 04:16:14,983 - training - INFO - Memory: GPU 0: 3818.9MB allocated, 9076.0MB reserved
2025-03-26 04:16:14,984 - training - INFO - Epoch: 42/200000, Batch: 15/45, Loss: 5.5001, Throughput: 77.65 samples/sec
2025-03-26 04:16:25,520 - training - INFO - Memory: GPU 0: 3817.4MB allocated, 9078.0MB reserved
2025-03-26 04:16:25,520 - training - INFO - Epoch: 42/200000, Batch: 30/45, Loss: 5.5174, Throughput: 78.64 samples/sec
2025-03-26 04:16:35,542 - training - INFO - Epoch 42 completed in 32.10s. Average loss: 5.4956
2025-03-26 04:16:35,545 - training - INFO - Starting epoch 43/200000
2025-03-26 04:16:36,235 - training - INFO - Memory: GPU 0: 3817.4MB allocated, 9202.0MB reserved
2025-03-26 04:16:36,235 - training - INFO - Epoch: 43/200000, Batch: 0/45, Loss: 5.4034, Throughput: 81.28 samples/sec
2025-03-26 04:16:46,964 - training - INFO - Memory: GPU 0: 3819.0MB allocated, 9080.0MB reserved
2025-03-26 04:16:46,964 - training - INFO - Epoch: 43/200000, Batch: 15/45, Loss: 5.5624, Throughput: 78.47 samples/sec
2025-03-26 04:16:57,425 - training - INFO - Memory: GPU 0: 3819.3MB allocated, 9082.0MB reserved
2025-03-26 04:16:57,425 - training - INFO - Epoch: 43/200000, Batch: 30/45, Loss: 5.5285, Throughput: 79.34 samples/sec
2025-03-26 04:17:07,340 - training - INFO - Epoch 43 completed in 31.80s. Average loss: 5.4869
2025-03-26 04:17:07,343 - training - INFO - Starting epoch 44/200000
2025-03-26 04:17:08,056 - training - INFO - Memory: GPU 0: 3815.3MB allocated, 9206.0MB reserved
2025-03-26 04:17:08,056 - training - INFO - Epoch: 44/200000, Batch: 0/45, Loss: 5.5846, Throughput: 78.75 samples/sec
2025-03-26 04:17:18,874 - training - INFO - Memory: GPU 0: 3818.9MB allocated, 9058.0MB reserved
2025-03-26 04:17:18,874 - training - INFO - Epoch: 44/200000, Batch: 15/45, Loss: 5.4616, Throughput: 77.72 samples/sec
2025-03-26 04:17:29,358 - training - INFO - Memory: GPU 0: 3820.5MB allocated, 9058.0MB reserved
2025-03-26 04:17:29,359 - training - INFO - Epoch: 44/200000, Batch: 30/45, Loss: 5.4959, Throughput: 78.86 samples/sec
2025-03-26 04:17:39,261 - training - INFO - Epoch 44 completed in 31.92s. Average loss: 5.4972
2025-03-26 04:17:39,264 - training - INFO - Starting epoch 45/200000
2025-03-26 04:17:39,957 - training - INFO - Memory: GPU 0: 3819.6MB allocated, 9182.0MB reserved
2025-03-26 04:17:39,958 - training - INFO - Epoch: 45/200000, Batch: 0/45, Loss: 5.5982, Throughput: 81.00 samples/sec
2025-03-26 04:17:50,873 - training - INFO - Memory: GPU 0: 3818.9MB allocated, 9072.0MB reserved
2025-03-26 04:17:50,874 - training - INFO - Epoch: 45/200000, Batch: 15/45, Loss: 5.4433, Throughput: 77.19 samples/sec
2025-03-26 04:18:01,443 - training - INFO - Memory: GPU 0: 3816.1MB allocated, 9072.0MB reserved
2025-03-26 04:18:01,443 - training - INFO - Epoch: 45/200000, Batch: 30/45, Loss: 5.4525, Throughput: 78.28 samples/sec
2025-03-26 04:18:11,340 - training - INFO - Epoch 45 completed in 32.08s. Average loss: 5.4888
2025-03-26 04:18:11,343 - training - INFO - Starting epoch 46/200000
2025-03-26 04:18:12,058 - training - INFO - Memory: GPU 0: 3817.8MB allocated, 9196.0MB reserved
2025-03-26 04:18:12,058 - training - INFO - Epoch: 46/200000, Batch: 0/45, Loss: 5.7020, Throughput: 78.55 samples/sec
2025-03-26 04:18:22,898 - training - INFO - Memory: GPU 0: 3814.5MB allocated, 9078.0MB reserved
2025-03-26 04:18:22,899 - training - INFO - Epoch: 46/200000, Batch: 15/45, Loss: 5.4645, Throughput: 77.56 samples/sec
2025-03-26 04:18:33,584 - training - INFO - Memory: GPU 0: 3816.2MB allocated, 9078.0MB reserved
2025-03-26 04:18:33,584 - training - INFO - Epoch: 46/200000, Batch: 30/45, Loss: 5.4875, Throughput: 78.06 samples/sec
2025-03-26 04:18:43,636 - training - INFO - Epoch 46 completed in 32.29s. Average loss: 5.4856
2025-03-26 04:18:43,639 - training - INFO - Starting epoch 47/200000
2025-03-26 04:18:44,336 - training - INFO - Memory: GPU 0: 3817.0MB allocated, 9202.0MB reserved
2025-03-26 04:18:44,336 - training - INFO - Epoch: 47/200000, Batch: 0/45, Loss: 5.5216, Throughput: 80.55 samples/sec
2025-03-26 04:18:55,289 - training - INFO - Memory: GPU 0: 3815.3MB allocated, 9062.0MB reserved
2025-03-26 04:18:55,290 - training - INFO - Epoch: 47/200000, Batch: 15/45, Loss: 5.4632, Throughput: 76.93 samples/sec
2025-03-26 04:19:05,899 - training - INFO - Memory: GPU 0: 3819.4MB allocated, 9062.0MB reserved
2025-03-26 04:19:05,899 - training - INFO - Epoch: 47/200000, Batch: 30/45, Loss: 5.4842, Throughput: 77.99 samples/sec
2025-03-26 04:19:15,830 - training - INFO - Epoch 47 completed in 32.19s. Average loss: 5.4798
2025-03-26 04:19:15,833 - training - INFO - Starting epoch 48/200000
2025-03-26 04:19:16,527 - training - INFO - Memory: GPU 0: 3819.6MB allocated, 9186.0MB reserved
2025-03-26 04:19:16,527 - training - INFO - Epoch: 48/200000, Batch: 0/45, Loss: 5.5122, Throughput: 80.92 samples/sec
2025-03-26 04:19:27,375 - training - INFO - Memory: GPU 0: 3819.8MB allocated, 9062.0MB reserved
2025-03-26 04:19:27,376 - training - INFO - Epoch: 48/200000, Batch: 15/45, Loss: 5.5139, Throughput: 77.64 samples/sec
2025-03-26 04:19:38,064 - training - INFO - Memory: GPU 0: 3815.6MB allocated, 9064.0MB reserved
2025-03-26 04:19:38,064 - training - INFO - Epoch: 48/200000, Batch: 30/45, Loss: 5.4801, Throughput: 78.10 samples/sec
2025-03-26 04:19:48,060 - training - INFO - Epoch 48 completed in 32.23s. Average loss: 5.4780
2025-03-26 04:19:48,064 - training - INFO - Starting epoch 49/200000
2025-03-26 04:19:48,745 - training - INFO - Memory: GPU 0: 3816.0MB allocated, 9188.0MB reserved
2025-03-26 04:19:48,745 - training - INFO - Epoch: 49/200000, Batch: 0/45, Loss: 5.6535, Throughput: 82.43 samples/sec
2025-03-26 04:19:59,528 - training - INFO - Memory: GPU 0: 3814.8MB allocated, 9044.0MB reserved
2025-03-26 04:19:59,528 - training - INFO - Epoch: 49/200000, Batch: 15/45, Loss: 5.5169, Throughput: 78.17 samples/sec
2025-03-26 04:20:10,028 - training - INFO - Memory: GPU 0: 3821.1MB allocated, 9044.0MB reserved
2025-03-26 04:20:10,028 - training - INFO - Epoch: 49/200000, Batch: 30/45, Loss: 5.5036, Throughput: 79.04 samples/sec
2025-03-26 04:20:19,979 - training - INFO - Epoch 49 completed in 31.92s. Average loss: 5.4765
2025-03-26 04:20:19,983 - training - INFO - Starting epoch 50/200000
2025-03-26 04:20:20,670 - training - INFO - Memory: GPU 0: 3819.1MB allocated, 9168.0MB reserved
2025-03-26 04:20:20,670 - training - INFO - Epoch: 50/200000, Batch: 0/45, Loss: 5.5183, Throughput: 81.72 samples/sec
2025-03-26 04:20:31,443 - training - INFO - Memory: GPU 0: 3813.6MB allocated, 9046.0MB reserved
2025-03-26 04:20:31,443 - training - INFO - Epoch: 50/200000, Batch: 15/45, Loss: 5.4537, Throughput: 78.20 samples/sec
2025-03-26 04:20:41,991 - training - INFO - Memory: GPU 0: 3813.0MB allocated, 9046.0MB reserved
2025-03-26 04:20:41,992 - training - INFO - Epoch: 50/200000, Batch: 30/45, Loss: 5.4506, Throughput: 78.89 samples/sec
2025-03-26 04:20:51,998 - training - INFO - Epoch 50 completed in 32.02s. Average loss: 5.4671
2025-03-26 04:20:52,001 - training - INFO - Starting validation...
2025-03-26 04:20:52,311 - training - INFO - Validation Loss: 6.2551
2025-03-26 04:20:52,311 - training - INFO - Validation loss improved significantly from 6.3260 to 6.2551
2025-03-26 04:20:52,526 - training - INFO - Starting epoch 51/200000
2025-03-26 04:20:53,252 - training - INFO - Memory: GPU 0: 3815.9MB allocated, 8504.0MB reserved
2025-03-26 04:20:53,252 - training - INFO - Epoch: 51/200000, Batch: 0/45, Loss: 5.3426, Throughput: 77.39 samples/sec
2025-03-26 04:21:04,039 - training - INFO - Memory: GPU 0: 3814.0MB allocated, 9056.0MB reserved
2025-03-26 04:21:04,040 - training - INFO - Epoch: 51/200000, Batch: 15/45, Loss: 5.4751, Throughput: 77.83 samples/sec
2025-03-26 04:21:14,698 - training - INFO - Memory: GPU 0: 3812.3MB allocated, 9056.0MB reserved
2025-03-26 04:21:14,699 - training - INFO - Epoch: 51/200000, Batch: 30/45, Loss: 5.4824, Throughput: 78.30 samples/sec
2025-03-26 04:21:24,746 - training - INFO - Epoch 51 completed in 32.22s. Average loss: 5.4687
2025-03-26 04:21:24,749 - training - INFO - Starting epoch 52/200000
2025-03-26 04:21:25,464 - training - INFO - Memory: GPU 0: 3811.7MB allocated, 9182.0MB reserved
2025-03-26 04:21:25,464 - training - INFO - Epoch: 52/200000, Batch: 0/45, Loss: 5.5858, Throughput: 78.52 samples/sec
2025-03-26 04:21:36,238 - training - INFO - Memory: GPU 0: 3811.9MB allocated, 9090.0MB reserved
2025-03-26 04:21:36,238 - training - INFO - Epoch: 52/200000, Batch: 15/45, Loss: 5.4594, Throughput: 77.99 samples/sec
2025-03-26 04:21:46,739 - training - INFO - Memory: GPU 0: 3812.9MB allocated, 9090.0MB reserved
2025-03-26 04:21:46,739 - training - INFO - Epoch: 52/200000, Batch: 30/45, Loss: 5.4721, Throughput: 78.95 samples/sec
2025-03-26 04:21:56,693 - training - INFO - Epoch 52 completed in 31.94s. Average loss: 5.4552
2025-03-26 04:21:56,697 - training - INFO - Starting epoch 53/200000
2025-03-26 04:21:57,379 - training - INFO - Memory: GPU 0: 3815.7MB allocated, 9216.0MB reserved
2025-03-26 04:21:57,379 - training - INFO - Epoch: 53/200000, Batch: 0/45, Loss: 5.5788, Throughput: 82.31 samples/sec
2025-03-26 04:22:08,241 - training - INFO - Memory: GPU 0: 3814.6MB allocated, 9070.0MB reserved
2025-03-26 04:22:08,241 - training - INFO - Epoch: 53/200000, Batch: 15/45, Loss: 5.3991, Throughput: 77.62 samples/sec
2025-03-26 04:22:18,810 - training - INFO - Memory: GPU 0: 3816.5MB allocated, 9070.0MB reserved
2025-03-26 04:22:18,810 - training - INFO - Epoch: 53/200000, Batch: 30/45, Loss: 5.4091, Throughput: 78.51 samples/sec
2025-03-26 04:22:28,722 - training - INFO - Epoch 53 completed in 32.03s. Average loss: 5.4585
2025-03-26 04:22:28,725 - training - INFO - Starting epoch 54/200000
2025-03-26 04:22:29,419 - training - INFO - Memory: GPU 0: 3813.7MB allocated, 9194.0MB reserved
2025-03-26 04:22:29,419 - training - INFO - Epoch: 54/200000, Batch: 0/45, Loss: 5.2492, Throughput: 80.98 samples/sec
2025-03-26 04:22:40,296 - training - INFO - Memory: GPU 0: 3814.2MB allocated, 9070.0MB reserved
2025-03-26 04:22:40,297 - training - INFO - Epoch: 54/200000, Batch: 15/45, Loss: 5.3841, Throughput: 77.44 samples/sec
2025-03-26 04:22:50,942 - training - INFO - Memory: GPU 0: 3817.3MB allocated, 9072.0MB reserved
2025-03-26 04:22:50,943 - training - INFO - Epoch: 54/200000, Batch: 30/45, Loss: 5.4284, Throughput: 78.14 samples/sec
2025-03-26 04:23:00,953 - training - INFO - Epoch 54 completed in 32.23s. Average loss: 5.4489
2025-03-26 04:23:00,956 - training - INFO - Starting epoch 55/200000
2025-03-26 04:23:01,621 - training - INFO - Memory: GPU 0: 3815.1MB allocated, 9196.0MB reserved
2025-03-26 04:23:01,622 - training - INFO - Epoch: 55/200000, Batch: 0/45, Loss: 5.7538, Throughput: 84.48 samples/sec
2025-03-26 04:23:12,484 - training - INFO - Memory: GPU 0: 3814.2MB allocated, 9066.0MB reserved
2025-03-26 04:23:12,484 - training - INFO - Epoch: 55/200000, Batch: 15/45, Loss: 5.4401, Throughput: 77.73 samples/sec
2025-03-26 04:23:23,048 - training - INFO - Memory: GPU 0: 3812.6MB allocated, 9066.0MB reserved
2025-03-26 04:23:23,049 - training - INFO - Epoch: 55/200000, Batch: 30/45, Loss: 5.4637, Throughput: 78.59 samples/sec
2025-03-26 04:23:33,032 - training - INFO - Epoch 55 completed in 32.08s. Average loss: 5.4474
2025-03-26 04:23:33,035 - training - INFO - Starting epoch 56/200000
2025-03-26 04:23:33,713 - training - INFO - Memory: GPU 0: 3815.0MB allocated, 9190.0MB reserved
2025-03-26 04:23:33,713 - training - INFO - Epoch: 56/200000, Batch: 0/45, Loss: 5.4120, Throughput: 82.72 samples/sec
2025-03-26 04:23:44,512 - training - INFO - Memory: GPU 0: 3816.9MB allocated, 9068.0MB reserved
2025-03-26 04:23:44,512 - training - INFO - Epoch: 56/200000, Batch: 15/45, Loss: 5.5016, Throughput: 78.08 samples/sec
2025-03-26 04:23:55,016 - training - INFO - Memory: GPU 0: 3817.7MB allocated, 9068.0MB reserved
2025-03-26 04:23:55,016 - training - INFO - Epoch: 56/200000, Batch: 30/45, Loss: 5.4241, Throughput: 78.98 samples/sec
2025-03-26 04:24:04,958 - training - INFO - Epoch 56 completed in 31.92s. Average loss: 5.4493
2025-03-26 04:24:04,963 - training - INFO - Starting epoch 57/200000
2025-03-26 04:24:05,653 - training - INFO - Memory: GPU 0: 3815.4MB allocated, 9192.0MB reserved
2025-03-26 04:24:05,653 - training - INFO - Epoch: 57/200000, Batch: 0/45, Loss: 5.6336, Throughput: 81.22 samples/sec
2025-03-26 04:24:16,446 - training - INFO - Memory: GPU 0: 3812.1MB allocated, 9072.0MB reserved
2025-03-26 04:24:16,446 - training - INFO - Epoch: 57/200000, Batch: 15/45, Loss: 5.4860, Throughput: 78.04 samples/sec
2025-03-26 04:24:26,993 - training - INFO - Memory: GPU 0: 3812.6MB allocated, 9072.0MB reserved
2025-03-26 04:24:26,994 - training - INFO - Epoch: 57/200000, Batch: 30/45, Loss: 5.4233, Throughput: 78.81 samples/sec
2025-03-26 04:24:36,983 - training - INFO - Epoch 57 completed in 32.02s. Average loss: 5.4473
2025-03-26 04:24:36,986 - training - INFO - Starting epoch 58/200000
2025-03-26 04:24:37,683 - training - INFO - Memory: GPU 0: 3811.9MB allocated, 9196.0MB reserved
2025-03-26 04:24:37,683 - training - INFO - Epoch: 58/200000, Batch: 0/45, Loss: 5.5553, Throughput: 80.46 samples/sec
2025-03-26 04:24:48,513 - training - INFO - Memory: GPU 0: 3816.1MB allocated, 9074.0MB reserved
2025-03-26 04:24:48,513 - training - INFO - Epoch: 58/200000, Batch: 15/45, Loss: 5.3261, Throughput: 77.74 samples/sec
2025-03-26 04:24:59,103 - training - INFO - Memory: GPU 0: 3817.1MB allocated, 9076.0MB reserved
2025-03-26 04:24:59,103 - training - INFO - Epoch: 58/200000, Batch: 30/45, Loss: 5.3883, Throughput: 78.50 samples/sec
2025-03-26 04:25:09,060 - training - INFO - Epoch 58 completed in 32.07s. Average loss: 5.4397
2025-03-26 04:25:09,063 - training - INFO - Starting epoch 59/200000
2025-03-26 04:25:09,759 - training - INFO - Memory: GPU 0: 3818.1MB allocated, 9198.0MB reserved
2025-03-26 04:25:09,759 - training - INFO - Epoch: 59/200000, Batch: 0/45, Loss: 5.3949, Throughput: 80.67 samples/sec
2025-03-26 04:25:20,581 - training - INFO - Memory: GPU 0: 3815.4MB allocated, 9060.0MB reserved
2025-03-26 04:25:20,582 - training - INFO - Epoch: 59/200000, Batch: 15/45, Loss: 5.4309, Throughput: 77.80 samples/sec
2025-03-26 04:25:31,217 - training - INFO - Memory: GPU 0: 3811.4MB allocated, 9060.0MB reserved
2025-03-26 04:25:31,218 - training - INFO - Epoch: 59/200000, Batch: 30/45, Loss: 5.4279, Throughput: 78.37 samples/sec
2025-03-26 04:25:41,258 - training - INFO - Epoch 59 completed in 32.19s. Average loss: 5.4405
2025-03-26 04:25:41,261 - training - INFO - Starting epoch 60/200000
2025-03-26 04:25:41,952 - training - INFO - Memory: GPU 0: 3815.9MB allocated, 9186.0MB reserved
2025-03-26 04:25:41,952 - training - INFO - Epoch: 60/200000, Batch: 0/45, Loss: 5.4060, Throughput: 81.27 samples/sec
2025-03-26 04:25:52,811 - training - INFO - Memory: GPU 0: 3813.4MB allocated, 9062.0MB reserved
2025-03-26 04:25:52,811 - training - INFO - Epoch: 60/200000, Batch: 15/45, Loss: 5.4612, Throughput: 77.59 samples/sec
2025-03-26 04:26:03,368 - training - INFO - Memory: GPU 0: 3811.8MB allocated, 9062.0MB reserved
2025-03-26 04:26:03,369 - training - INFO - Epoch: 60/200000, Batch: 30/45, Loss: 5.4638, Throughput: 78.53 samples/sec
2025-03-26 04:26:13,355 - training - INFO - Epoch 60 completed in 32.09s. Average loss: 5.4363
2025-03-26 04:26:13,358 - training - INFO - Starting validation...
2025-03-26 04:26:13,670 - training - INFO - Validation Loss: 6.2524
2025-03-26 04:26:13,670 - training - INFO - Validation loss improved from previous (6.2551 to 6.2524) but not better than best (6.2551). Counter reduced to 0.
2025-03-26 04:26:13,907 - training - INFO - Starting epoch 61/200000
2025-03-26 04:26:14,590 - training - INFO - Memory: GPU 0: 3812.7MB allocated, 8542.0MB reserved
2025-03-26 04:26:14,590 - training - INFO - Epoch: 61/200000, Batch: 0/45, Loss: 5.3812, Throughput: 82.14 samples/sec
2025-03-26 04:26:25,250 - training - INFO - Memory: GPU 0: 3813.5MB allocated, 9078.0MB reserved
2025-03-26 04:26:25,251 - training - INFO - Epoch: 61/200000, Batch: 15/45, Loss: 5.4517, Throughput: 79.00 samples/sec
2025-03-26 04:26:35,816 - training - INFO - Memory: GPU 0: 3815.2MB allocated, 9078.0MB reserved
2025-03-26 04:26:35,817 - training - INFO - Epoch: 61/200000, Batch: 30/45, Loss: 5.4576, Throughput: 79.24 samples/sec
2025-03-26 04:26:45,706 - training - INFO - Epoch 61 completed in 31.80s. Average loss: 5.4399
2025-03-26 04:26:45,709 - training - INFO - Starting epoch 62/200000
2025-03-26 04:26:46,395 - training - INFO - Memory: GPU 0: 3814.5MB allocated, 9204.0MB reserved
2025-03-26 04:26:46,395 - training - INFO - Epoch: 62/200000, Batch: 0/45, Loss: 5.4303, Throughput: 81.94 samples/sec
2025-03-26 04:26:57,153 - training - INFO - Memory: GPU 0: 3814.2MB allocated, 9072.0MB reserved
2025-03-26 04:26:57,153 - training - INFO - Epoch: 62/200000, Batch: 15/45, Loss: 5.4553, Throughput: 78.31 samples/sec
2025-03-26 04:27:07,629 - training - INFO - Memory: GPU 0: 3815.1MB allocated, 9074.0MB reserved
2025-03-26 04:27:07,629 - training - INFO - Epoch: 62/200000, Batch: 30/45, Loss: 5.4815, Throughput: 79.21 samples/sec
2025-03-26 04:27:17,574 - training - INFO - Epoch 62 completed in 31.87s. Average loss: 5.4272
2025-03-26 04:27:17,578 - training - INFO - Starting epoch 63/200000
2025-03-26 04:27:18,287 - training - INFO - Memory: GPU 0: 3816.2MB allocated, 9198.0MB reserved
2025-03-26 04:27:18,287 - training - INFO - Epoch: 63/200000, Batch: 0/45, Loss: 5.2371, Throughput: 79.07 samples/sec
2025-03-26 04:27:29,085 - training - INFO - Memory: GPU 0: 3821.1MB allocated, 9094.0MB reserved
2025-03-26 04:27:29,086 - training - INFO - Epoch: 63/200000, Batch: 15/45, Loss: 5.4511, Throughput: 77.88 samples/sec
2025-03-26 04:27:39,639 - training - INFO - Memory: GPU 0: 3815.5MB allocated, 9094.0MB reserved
2025-03-26 04:27:39,640 - training - INFO - Epoch: 63/200000, Batch: 30/45, Loss: 5.4056, Throughput: 78.70 samples/sec
2025-03-26 04:27:49,617 - training - INFO - Epoch 63 completed in 32.04s. Average loss: 5.4238
2025-03-26 04:27:49,620 - training - INFO - Starting epoch 64/200000
2025-03-26 04:27:50,330 - training - INFO - Memory: GPU 0: 3817.0MB allocated, 9218.0MB reserved
2025-03-26 04:27:50,330 - training - INFO - Epoch: 64/200000, Batch: 0/45, Loss: 5.4040, Throughput: 79.10 samples/sec
2025-03-26 04:28:01,110 - training - INFO - Memory: GPU 0: 3816.9MB allocated, 9074.0MB reserved
2025-03-26 04:28:01,110 - training - INFO - Epoch: 64/200000, Batch: 15/45, Loss: 5.3908, Throughput: 77.99 samples/sec
2025-03-26 04:28:11,804 - training - INFO - Memory: GPU 0: 3813.5MB allocated, 9074.0MB reserved
2025-03-26 04:28:11,805 - training - INFO - Epoch: 64/200000, Batch: 30/45, Loss: 5.4163, Throughput: 78.26 samples/sec
2025-03-26 04:28:21,799 - training - INFO - Epoch 64 completed in 32.18s. Average loss: 5.4339
2025-03-26 04:28:21,802 - training - INFO - Starting epoch 65/200000
2025-03-26 04:28:22,494 - training - INFO - Memory: GPU 0: 3815.8MB allocated, 9196.0MB reserved
2025-03-26 04:28:22,495 - training - INFO - Epoch: 65/200000, Batch: 0/45, Loss: 5.0419, Throughput: 81.08 samples/sec
2025-03-26 04:28:33,258 - training - INFO - Memory: GPU 0: 3814.2MB allocated, 9090.0MB reserved
2025-03-26 04:28:33,258 - training - INFO - Epoch: 65/200000, Batch: 15/45, Loss: 5.4474, Throughput: 78.22 samples/sec
2025-03-26 04:28:43,899 - training - INFO - Memory: GPU 0: 3814.7MB allocated, 9092.0MB reserved
2025-03-26 04:28:43,899 - training - INFO - Epoch: 65/200000, Batch: 30/45, Loss: 5.4131, Throughput: 78.57 samples/sec
2025-03-26 04:28:53,799 - training - INFO - Epoch 65 completed in 32.00s. Average loss: 5.4286
2025-03-26 04:28:53,802 - training - INFO - Starting epoch 66/200000
2025-03-26 04:28:54,499 - training - INFO - Memory: GPU 0: 3813.9MB allocated, 9214.0MB reserved
2025-03-26 04:28:54,499 - training - INFO - Epoch: 66/200000, Batch: 0/45, Loss: 5.5500, Throughput: 80.56 samples/sec
2025-03-26 04:29:05,260 - training - INFO - Memory: GPU 0: 3817.5MB allocated, 9080.0MB reserved
2025-03-26 04:29:05,261 - training - INFO - Epoch: 66/200000, Batch: 15/45, Loss: 5.4343, Throughput: 78.22 samples/sec
2025-03-26 04:29:15,850 - training - INFO - Memory: GPU 0: 3814.9MB allocated, 9080.0MB reserved
2025-03-26 04:29:15,851 - training - INFO - Epoch: 66/200000, Batch: 30/45, Loss: 5.4238, Throughput: 78.74 samples/sec
2025-03-26 04:29:25,871 - training - INFO - Epoch 66 completed in 32.07s. Average loss: 5.4364
2025-03-26 04:29:25,875 - training - INFO - Starting epoch 67/200000
2025-03-26 04:29:26,560 - training - INFO - Memory: GPU 0: 3819.1MB allocated, 9206.0MB reserved
2025-03-26 04:29:26,561 - training - INFO - Epoch: 67/200000, Batch: 0/45, Loss: 5.4968, Throughput: 81.83 samples/sec
2025-03-26 04:29:37,452 - training - INFO - Memory: GPU 0: 3822.1MB allocated, 9072.0MB reserved
2025-03-26 04:29:37,453 - training - INFO - Epoch: 67/200000, Batch: 15/45, Loss: 5.4722, Throughput: 77.40 samples/sec
2025-03-26 04:29:48,053 - training - INFO - Memory: GPU 0: 3815.0MB allocated, 9072.0MB reserved
2025-03-26 04:29:48,054 - training - INFO - Epoch: 67/200000, Batch: 30/45, Loss: 5.4190, Throughput: 78.28 samples/sec
2025-03-26 04:29:58,023 - training - INFO - Epoch 67 completed in 32.15s. Average loss: 5.4246
2025-03-26 04:29:58,026 - training - INFO - Starting epoch 68/200000
2025-03-26 04:29:58,727 - training - INFO - Memory: GPU 0: 3815.3MB allocated, 9198.0MB reserved
2025-03-26 04:29:58,727 - training - INFO - Epoch: 68/200000, Batch: 0/45, Loss: 5.5396, Throughput: 80.17 samples/sec
2025-03-26 04:30:09,459 - training - INFO - Memory: GPU 0: 3817.9MB allocated, 9094.0MB reserved
2025-03-26 04:30:09,459 - training - INFO - Epoch: 68/200000, Batch: 15/45, Loss: 5.4580, Throughput: 78.38 samples/sec
2025-03-26 04:30:19,961 - training - INFO - Memory: GPU 0: 3816.6MB allocated, 9094.0MB reserved
2025-03-26 04:30:19,962 - training - INFO - Epoch: 68/200000, Batch: 30/45, Loss: 5.4280, Throughput: 79.15 samples/sec
2025-03-26 04:30:29,845 - training - INFO - Epoch 68 completed in 31.82s. Average loss: 5.4059
2025-03-26 04:30:29,849 - training - INFO - Starting epoch 69/200000
2025-03-26 04:30:30,553 - training - INFO - Memory: GPU 0: 3816.1MB allocated, 9216.0MB reserved
2025-03-26 04:30:30,554 - training - INFO - Epoch: 69/200000, Batch: 0/45, Loss: 5.3992, Throughput: 79.66 samples/sec
2025-03-26 04:30:41,352 - training - INFO - Memory: GPU 0: 3814.6MB allocated, 9086.0MB reserved
2025-03-26 04:30:41,353 - training - INFO - Epoch: 69/200000, Batch: 15/45, Loss: 5.3586, Throughput: 77.91 samples/sec
2025-03-26 04:30:51,871 - training - INFO - Memory: GPU 0: 3816.9MB allocated, 9086.0MB reserved
2025-03-26 04:30:51,871 - training - INFO - Epoch: 69/200000, Batch: 30/45, Loss: 5.4063, Throughput: 78.83 samples/sec
2025-03-26 04:31:01,777 - training - INFO - Epoch 69 completed in 31.93s. Average loss: 5.4105
2025-03-26 04:31:01,780 - training - INFO - Starting epoch 70/200000
2025-03-26 04:31:02,464 - training - INFO - Memory: GPU 0: 3814.7MB allocated, 9210.0MB reserved
2025-03-26 04:31:02,465 - training - INFO - Epoch: 70/200000, Batch: 0/45, Loss: 5.2269, Throughput: 82.03 samples/sec
2025-03-26 04:31:13,255 - training - INFO - Memory: GPU 0: 3813.7MB allocated, 9072.0MB reserved
2025-03-26 04:31:13,255 - training - INFO - Epoch: 70/200000, Batch: 15/45, Loss: 5.4393, Throughput: 78.09 samples/sec
2025-03-26 04:31:23,848 - training - INFO - Memory: GPU 0: 3813.2MB allocated, 9072.0MB reserved
2025-03-26 04:31:23,848 - training - INFO - Epoch: 70/200000, Batch: 30/45, Loss: 5.4224, Throughput: 78.67 samples/sec
2025-03-26 04:31:33,754 - training - INFO - Epoch 70 completed in 31.97s. Average loss: 5.4066
2025-03-26 04:31:33,757 - training - INFO - Starting validation...
2025-03-26 04:31:34,078 - training - INFO - Validation Loss: 6.2477
2025-03-26 04:31:34,078 - training - INFO - Validation loss improved from previous (6.2524 to 6.2477) but not better than best (6.2524). Counter reduced to 0.
2025-03-26 04:31:34,299 - training - INFO - Starting epoch 71/200000
2025-03-26 04:31:35,019 - training - INFO - Memory: GPU 0: 3813.8MB allocated, 8578.0MB reserved
2025-03-26 04:31:35,019 - training - INFO - Epoch: 71/200000, Batch: 0/45, Loss: 5.4722, Throughput: 77.86 samples/sec
2025-03-26 04:31:45,738 - training - INFO - Memory: GPU 0: 3809.5MB allocated, 9054.0MB reserved
2025-03-26 04:31:45,738 - training - INFO - Epoch: 71/200000, Batch: 15/45, Loss: 5.3403, Throughput: 78.34 samples/sec
2025-03-26 04:31:56,305 - training - INFO - Memory: GPU 0: 3811.6MB allocated, 9054.0MB reserved
2025-03-26 04:31:56,305 - training - INFO - Epoch: 71/200000, Batch: 30/45, Loss: 5.3813, Throughput: 78.89 samples/sec
2025-03-26 04:32:06,268 - training - INFO - Epoch 71 completed in 31.97s. Average loss: 5.3945
2025-03-26 04:32:06,272 - training - INFO - Starting epoch 72/200000
2025-03-26 04:32:06,956 - training - INFO - Memory: GPU 0: 3811.1MB allocated, 9178.0MB reserved
2025-03-26 04:32:06,956 - training - INFO - Epoch: 72/200000, Batch: 0/45, Loss: 5.3723, Throughput: 81.94 samples/sec
2025-03-26 04:32:17,731 - training - INFO - Memory: GPU 0: 3814.8MB allocated, 9060.0MB reserved
2025-03-26 04:32:17,732 - training - INFO - Epoch: 72/200000, Batch: 15/45, Loss: 5.3810, Throughput: 78.19 samples/sec
2025-03-26 04:32:28,381 - training - INFO - Memory: GPU 0: 3813.1MB allocated, 9060.0MB reserved
2025-03-26 04:32:28,381 - training - INFO - Epoch: 72/200000, Batch: 30/45, Loss: 5.4222, Throughput: 78.52 samples/sec
2025-03-26 04:32:38,323 - training - INFO - Epoch 72 completed in 32.05s. Average loss: 5.3946
2025-03-26 04:32:38,326 - training - INFO - Starting epoch 73/200000
2025-03-26 04:32:39,009 - training - INFO - Memory: GPU 0: 3809.1MB allocated, 9184.0MB reserved
2025-03-26 04:32:39,010 - training - INFO - Epoch: 73/200000, Batch: 0/45, Loss: 5.6240, Throughput: 82.22 samples/sec
2025-03-26 04:32:49,938 - training - INFO - Memory: GPU 0: 3813.9MB allocated, 9080.0MB reserved
2025-03-26 04:32:49,939 - training - INFO - Epoch: 73/200000, Batch: 15/45, Loss: 5.4099, Throughput: 77.17 samples/sec
2025-03-26 04:33:00,585 - training - INFO - Memory: GPU 0: 3811.7MB allocated, 9080.0MB reserved
2025-03-26 04:33:00,586 - training - INFO - Epoch: 73/200000, Batch: 30/45, Loss: 5.3975, Throughput: 78.00 samples/sec
2025-03-26 04:33:10,492 - training - INFO - Epoch 73 completed in 32.17s. Average loss: 5.3991
2025-03-26 04:33:10,495 - training - INFO - Starting epoch 74/200000
2025-03-26 04:33:11,195 - training - INFO - Memory: GPU 0: 3812.1MB allocated, 9204.0MB reserved
2025-03-26 04:33:11,195 - training - INFO - Epoch: 74/200000, Batch: 0/45, Loss: 5.3617, Throughput: 80.12 samples/sec
2025-03-26 04:33:22,091 - training - INFO - Memory: GPU 0: 3811.2MB allocated, 9060.0MB reserved
2025-03-26 04:33:22,092 - training - INFO - Epoch: 74/200000, Batch: 15/45, Loss: 5.4090, Throughput: 77.29 samples/sec
2025-03-26 04:33:32,788 - training - INFO - Memory: GPU 0: 3810.1MB allocated, 9060.0MB reserved
2025-03-26 04:33:32,788 - training - INFO - Epoch: 74/200000, Batch: 30/45, Loss: 5.4306, Throughput: 77.88 samples/sec
2025-03-26 04:33:42,709 - training - INFO - Epoch 74 completed in 32.21s. Average loss: 5.3888
2025-03-26 04:33:42,712 - training - INFO - Starting epoch 75/200000
2025-03-26 04:33:43,412 - training - INFO - Memory: GPU 0: 3811.6MB allocated, 9184.0MB reserved
2025-03-26 04:33:43,412 - training - INFO - Epoch: 75/200000, Batch: 0/45, Loss: 5.4424, Throughput: 80.26 samples/sec
2025-03-26 04:33:54,189 - training - INFO - Memory: GPU 0: 3811.6MB allocated, 9060.0MB reserved
2025-03-26 04:33:54,190 - training - INFO - Epoch: 75/200000, Batch: 15/45, Loss: 5.4174, Throughput: 78.08 samples/sec
2025-03-26 04:34:04,671 - training - INFO - Memory: GPU 0: 3810.2MB allocated, 9060.0MB reserved
2025-03-26 04:34:04,671 - training - INFO - Epoch: 75/200000, Batch: 30/45, Loss: 5.4029, Throughput: 79.07 samples/sec
2025-03-26 04:34:14,723 - training - INFO - Epoch 75 completed in 32.01s. Average loss: 5.3833
2025-03-26 04:34:14,727 - training - INFO - Starting epoch 76/200000
2025-03-26 04:34:15,415 - training - INFO - Memory: GPU 0: 3809.3MB allocated, 9184.0MB reserved
2025-03-26 04:34:15,415 - training - INFO - Epoch: 76/200000, Batch: 0/45, Loss: 5.5429, Throughput: 81.49 samples/sec
2025-03-26 04:34:26,248 - training - INFO - Memory: GPU 0: 3809.0MB allocated, 9056.0MB reserved
2025-03-26 04:34:26,248 - training - INFO - Epoch: 76/200000, Batch: 15/45, Loss: 5.3382, Throughput: 77.79 samples/sec
2025-03-26 04:34:36,780 - training - INFO - Memory: GPU 0: 3814.4MB allocated, 9056.0MB reserved
2025-03-26 04:34:36,781 - training - INFO - Epoch: 76/200000, Batch: 30/45, Loss: 5.3834, Throughput: 78.72 samples/sec
2025-03-26 04:34:46,768 - training - INFO - Epoch 76 completed in 32.04s. Average loss: 5.3769
2025-03-26 04:34:46,773 - training - INFO - Starting epoch 77/200000
2025-03-26 04:34:47,461 - training - INFO - Memory: GPU 0: 3811.7MB allocated, 9180.0MB reserved
2025-03-26 04:34:47,462 - training - INFO - Epoch: 77/200000, Batch: 0/45, Loss: 5.4170, Throughput: 81.51 samples/sec
2025-03-26 04:34:58,392 - training - INFO - Memory: GPU 0: 3810.7MB allocated, 9062.0MB reserved
2025-03-26 04:34:58,392 - training - INFO - Epoch: 77/200000, Batch: 15/45, Loss: 5.3450, Throughput: 77.13 samples/sec
2025-03-26 04:35:08,944 - training - INFO - Memory: GPU 0: 3813.2MB allocated, 9062.0MB reserved
2025-03-26 04:35:08,944 - training - INFO - Epoch: 77/200000, Batch: 30/45, Loss: 5.3596, Throughput: 78.30 samples/sec
2025-03-26 04:35:18,874 - training - INFO - Epoch 77 completed in 32.10s. Average loss: 5.3626
2025-03-26 04:35:18,878 - training - INFO - Starting epoch 78/200000
2025-03-26 04:35:19,563 - training - INFO - Memory: GPU 0: 3816.5MB allocated, 9186.0MB reserved
2025-03-26 04:35:19,563 - training - INFO - Epoch: 78/200000, Batch: 0/45, Loss: 5.6077, Throughput: 82.01 samples/sec
2025-03-26 04:35:30,427 - training - INFO - Memory: GPU 0: 3812.8MB allocated, 9066.0MB reserved
2025-03-26 04:35:30,427 - training - INFO - Epoch: 78/200000, Batch: 15/45, Loss: 5.4389, Throughput: 77.59 samples/sec
2025-03-26 04:35:40,993 - training - INFO - Memory: GPU 0: 3815.6MB allocated, 9066.0MB reserved
2025-03-26 04:35:40,993 - training - INFO - Epoch: 78/200000, Batch: 30/45, Loss: 5.4138, Throughput: 78.51 samples/sec
2025-03-26 04:35:50,931 - training - INFO - Epoch 78 completed in 32.05s. Average loss: 5.3655
2025-03-26 04:35:50,934 - training - INFO - Starting epoch 79/200000
2025-03-26 04:35:51,618 - training - INFO - Memory: GPU 0: 3812.8MB allocated, 9190.0MB reserved
2025-03-26 04:35:51,618 - training - INFO - Epoch: 79/200000, Batch: 0/45, Loss: 5.2100, Throughput: 81.92 samples/sec
2025-03-26 04:36:02,448 - training - INFO - Memory: GPU 0: 3814.7MB allocated, 9058.0MB reserved
2025-03-26 04:36:02,449 - training - INFO - Epoch: 79/200000, Batch: 15/45, Loss: 5.4293, Throughput: 77.82 samples/sec
2025-03-26 04:36:13,054 - training - INFO - Memory: GPU 0: 3812.7MB allocated, 9058.0MB reserved
2025-03-26 04:36:13,054 - training - INFO - Epoch: 79/200000, Batch: 30/45, Loss: 5.3717, Throughput: 78.48 samples/sec
2025-03-26 04:36:23,006 - training - INFO - Epoch 79 completed in 32.07s. Average loss: 5.3689
2025-03-26 04:36:23,009 - training - INFO - Starting epoch 80/200000
2025-03-26 04:36:23,702 - training - INFO - Memory: GPU 0: 3813.1MB allocated, 9182.0MB reserved
2025-03-26 04:36:23,754 - training - INFO - Epoch: 80/200000, Batch: 0/45, Loss: 5.3704, Throughput: 81.04 samples/sec
2025-03-26 04:36:34,430 - training - INFO - Memory: GPU 0: 3812.2MB allocated, 9096.0MB reserved
2025-03-26 04:36:34,430 - training - INFO - Epoch: 80/200000, Batch: 15/45, Loss: 5.3201, Throughput: 78.47 samples/sec
2025-03-26 04:36:44,936 - training - INFO - Memory: GPU 0: 3813.4MB allocated, 9096.0MB reserved
2025-03-26 04:36:44,937 - training - INFO - Epoch: 80/200000, Batch: 30/45, Loss: 5.2602, Throughput: 79.18 samples/sec
2025-03-26 04:36:54,923 - training - INFO - Epoch 80 completed in 31.91s. Average loss: 5.3557
2025-03-26 04:36:54,926 - training - INFO - Starting validation...
2025-03-26 04:36:55,239 - training - INFO - Validation Loss: 6.2134
2025-03-26 04:36:55,239 - training - INFO - Validation loss improved significantly from 6.2477 to 6.2134
2025-03-26 04:36:55,487 - training - INFO - Starting epoch 81/200000
2025-03-26 04:36:56,166 - training - INFO - Memory: GPU 0: 3815.3MB allocated, 8456.0MB reserved
2025-03-26 04:36:56,166 - training - INFO - Epoch: 81/200000, Batch: 0/45, Loss: 5.3403, Throughput: 82.64 samples/sec
2025-03-26 04:37:06,867 - training - INFO - Memory: GPU 0: 3815.3MB allocated, 9062.0MB reserved
2025-03-26 04:37:06,867 - training - INFO - Epoch: 81/200000, Batch: 15/45, Loss: 5.3188, Throughput: 78.75 samples/sec
2025-03-26 04:37:17,504 - training - INFO - Memory: GPU 0: 3817.7MB allocated, 9062.0MB reserved
2025-03-26 04:37:17,504 - training - INFO - Epoch: 81/200000, Batch: 30/45, Loss: 5.3154, Throughput: 78.86 samples/sec
2025-03-26 04:37:27,600 - training - INFO - Epoch 81 completed in 32.11s. Average loss: 5.3458
2025-03-26 04:37:27,603 - training - INFO - Starting epoch 82/200000
2025-03-26 04:37:28,299 - training - INFO - Memory: GPU 0: 3813.4MB allocated, 9186.0MB reserved
2025-03-26 04:37:28,299 - training - INFO - Epoch: 82/200000, Batch: 0/45, Loss: 5.0331, Throughput: 80.75 samples/sec
2025-03-26 04:37:39,228 - training - INFO - Memory: GPU 0: 3814.4MB allocated, 9086.0MB reserved
2025-03-26 04:37:39,228 - training - INFO - Epoch: 82/200000, Batch: 15/45, Loss: 5.3508, Throughput: 77.09 samples/sec
2025-03-26 04:37:49,921 - training - INFO - Memory: GPU 0: 3810.4MB allocated, 9086.0MB reserved
2025-03-26 04:37:49,921 - training - INFO - Epoch: 82/200000, Batch: 30/45, Loss: 5.3440, Throughput: 77.79 samples/sec
2025-03-26 04:37:59,807 - training - INFO - Epoch 82 completed in 32.20s. Average loss: 5.3489
2025-03-26 04:37:59,810 - training - INFO - Starting epoch 83/200000
2025-03-26 04:38:00,521 - training - INFO - Memory: GPU 0: 3809.6MB allocated, 9210.0MB reserved
2025-03-26 04:38:00,521 - training - INFO - Epoch: 83/200000, Batch: 0/45, Loss: 5.2351, Throughput: 78.98 samples/sec
2025-03-26 04:38:11,280 - training - INFO - Memory: GPU 0: 3811.6MB allocated, 9078.0MB reserved
2025-03-26 04:38:11,280 - training - INFO - Epoch: 83/200000, Batch: 15/45, Loss: 5.3642, Throughput: 78.13 samples/sec
2025-03-26 04:38:21,840 - training - INFO - Memory: GPU 0: 3812.2MB allocated, 9078.0MB reserved
2025-03-26 04:38:21,841 - training - INFO - Epoch: 83/200000, Batch: 30/45, Loss: 5.3144, Throughput: 78.81 samples/sec
2025-03-26 04:38:31,736 - training - INFO - Epoch 83 completed in 31.93s. Average loss: 5.3382
2025-03-26 04:38:31,739 - training - INFO - Starting epoch 84/200000
2025-03-26 04:38:32,426 - training - INFO - Memory: GPU 0: 3812.7MB allocated, 9202.0MB reserved
2025-03-26 04:38:32,426 - training - INFO - Epoch: 84/200000, Batch: 0/45, Loss: 5.2238, Throughput: 81.60 samples/sec
2025-03-26 04:38:43,200 - training - INFO - Memory: GPU 0: 3814.1MB allocated, 9082.0MB reserved
2025-03-26 04:38:43,200 - training - INFO - Epoch: 84/200000, Batch: 15/45, Loss: 5.3682, Throughput: 78.19 samples/sec
2025-03-26 04:38:53,761 - training - INFO - Memory: GPU 0: 3813.4MB allocated, 9082.0MB reserved
2025-03-26 04:38:53,761 - training - INFO - Epoch: 84/200000, Batch: 30/45, Loss: 5.3632, Throughput: 78.83 samples/sec
2025-03-26 04:39:03,634 - training - INFO - Epoch 84 completed in 31.89s. Average loss: 5.3303
2025-03-26 04:39:03,638 - training - INFO - Starting epoch 85/200000
2025-03-26 04:39:04,348 - training - INFO - Memory: GPU 0: 3809.5MB allocated, 9206.0MB reserved
2025-03-26 04:39:04,348 - training - INFO - Epoch: 85/200000, Batch: 0/45, Loss: 5.6723, Throughput: 79.05 samples/sec
2025-03-26 04:39:15,231 - training - INFO - Memory: GPU 0: 3813.6MB allocated, 9072.0MB reserved
2025-03-26 04:39:15,231 - training - INFO - Epoch: 85/200000, Batch: 15/45, Loss: 5.3501, Throughput: 77.30 samples/sec
2025-03-26 04:39:25,872 - training - INFO - Memory: GPU 0: 3812.3MB allocated, 9072.0MB reserved
2025-03-26 04:39:25,873 - training - INFO - Epoch: 85/200000, Batch: 30/45, Loss: 5.3375, Throughput: 78.08 samples/sec
2025-03-26 04:39:35,916 - training - INFO - Epoch 85 completed in 32.28s. Average loss: 5.3165
2025-03-26 04:39:35,919 - training - INFO - Starting epoch 86/200000
2025-03-26 04:39:36,608 - training - INFO - Memory: GPU 0: 3813.6MB allocated, 9196.0MB reserved
2025-03-26 04:39:36,608 - training - INFO - Epoch: 86/200000, Batch: 0/45, Loss: 5.3099, Throughput: 81.49 samples/sec
2025-03-26 04:39:47,526 - training - INFO - Memory: GPU 0: 3811.8MB allocated, 9092.0MB reserved
2025-03-26 04:39:47,526 - training - INFO - Epoch: 86/200000, Batch: 15/45, Loss: 5.2434, Throughput: 77.20 samples/sec
2025-03-26 04:39:58,093 - training - INFO - Memory: GPU 0: 3812.4MB allocated, 9092.0MB reserved
2025-03-26 04:39:58,093 - training - INFO - Epoch: 86/200000, Batch: 30/45, Loss: 5.3108, Throughput: 78.29 samples/sec
2025-03-26 04:40:08,056 - training - INFO - Epoch 86 completed in 32.14s. Average loss: 5.3078
2025-03-26 04:40:08,060 - training - INFO - Starting epoch 87/200000
2025-03-26 04:40:08,753 - training - INFO - Memory: GPU 0: 3813.3MB allocated, 9218.0MB reserved
2025-03-26 04:40:08,753 - training - INFO - Epoch: 87/200000, Batch: 0/45, Loss: 5.4715, Throughput: 80.88 samples/sec
2025-03-26 04:40:19,559 - training - INFO - Memory: GPU 0: 3819.5MB allocated, 9084.0MB reserved
2025-03-26 04:40:19,559 - training - INFO - Epoch: 87/200000, Batch: 15/45, Loss: 5.3694, Throughput: 77.92 samples/sec
2025-03-26 04:40:30,274 - training - INFO - Memory: GPU 0: 3815.0MB allocated, 9084.0MB reserved
2025-03-26 04:40:30,275 - training - INFO - Epoch: 87/200000, Batch: 30/45, Loss: 5.3070, Throughput: 78.15 samples/sec
2025-03-26 04:40:40,288 - training - INFO - Epoch 87 completed in 32.23s. Average loss: 5.3143
2025-03-26 04:40:40,291 - training - INFO - Starting epoch 88/200000
2025-03-26 04:40:40,977 - training - INFO - Memory: GPU 0: 3817.2MB allocated, 9210.0MB reserved
2025-03-26 04:40:40,978 - training - INFO - Epoch: 88/200000, Batch: 0/45, Loss: 5.2522, Throughput: 81.84 samples/sec
2025-03-26 04:40:51,695 - training - INFO - Memory: GPU 0: 3813.1MB allocated, 9074.0MB reserved
2025-03-26 04:40:51,695 - training - INFO - Epoch: 88/200000, Batch: 15/45, Loss: 5.2989, Throughput: 78.59 samples/sec
2025-03-26 04:41:02,273 - training - INFO - Memory: GPU 0: 3810.5MB allocated, 9074.0MB reserved
2025-03-26 04:41:02,273 - training - INFO - Epoch: 88/200000, Batch: 30/45, Loss: 5.3011, Throughput: 78.98 samples/sec
2025-03-26 04:41:12,217 - training - INFO - Epoch 88 completed in 31.93s. Average loss: 5.3046
2025-03-26 04:41:12,220 - training - INFO - Starting epoch 89/200000
2025-03-26 04:41:12,913 - training - INFO - Memory: GPU 0: 3814.5MB allocated, 9198.0MB reserved
2025-03-26 04:41:12,914 - training - INFO - Epoch: 89/200000, Batch: 0/45, Loss: 5.3230, Throughput: 81.00 samples/sec
2025-03-26 04:41:23,724 - training - INFO - Memory: GPU 0: 3815.0MB allocated, 9080.0MB reserved
2025-03-26 04:41:23,724 - training - INFO - Epoch: 89/200000, Batch: 15/45, Loss: 5.2389, Throughput: 77.90 samples/sec
2025-03-26 04:41:34,323 - training - INFO - Memory: GPU 0: 3812.0MB allocated, 9080.0MB reserved
2025-03-26 04:41:34,324 - training - INFO - Epoch: 89/200000, Batch: 30/45, Loss: 5.2301, Throughput: 78.55 samples/sec
2025-03-26 04:41:44,305 - training - INFO - Epoch 89 completed in 32.08s. Average loss: 5.2857
2025-03-26 04:41:44,308 - training - INFO - Starting epoch 90/200000
2025-03-26 04:41:44,994 - training - INFO - Memory: GPU 0: 3807.9MB allocated, 9206.0MB reserved
2025-03-26 04:41:44,994 - training - INFO - Epoch: 90/200000, Batch: 0/45, Loss: 5.3056, Throughput: 81.85 samples/sec
2025-03-26 04:41:55,807 - training - INFO - Memory: GPU 0: 3810.2MB allocated, 9084.0MB reserved
2025-03-26 04:41:55,808 - training - INFO - Epoch: 90/200000, Batch: 15/45, Loss: 5.3222, Throughput: 77.93 samples/sec
2025-03-26 04:42:06,465 - training - INFO - Memory: GPU 0: 3812.3MB allocated, 9084.0MB reserved
2025-03-26 04:42:06,465 - training - INFO - Epoch: 90/200000, Batch: 30/45, Loss: 5.3228, Throughput: 78.36 samples/sec
2025-03-26 04:42:16,378 - training - INFO - Epoch 90 completed in 32.07s. Average loss: 5.3000
2025-03-26 04:42:16,381 - training - INFO - Starting validation...
2025-03-26 04:42:16,697 - training - INFO - Validation Loss: 6.2177
2025-03-26 04:42:16,697 - training - INFO - Validation loss did not improve. Counter: 1/10
2025-03-26 04:42:16,942 - training - INFO - Starting epoch 91/200000
2025-03-26 04:42:17,639 - training - INFO - Memory: GPU 0: 3813.1MB allocated, 8532.0MB reserved
2025-03-26 04:42:17,639 - training - INFO - Epoch: 91/200000, Batch: 0/45, Loss: 4.9704, Throughput: 80.49 samples/sec
2025-03-26 04:42:28,299 - training - INFO - Memory: GPU 0: 3813.6MB allocated, 9070.0MB reserved
2025-03-26 04:42:28,299 - training - INFO - Epoch: 91/200000, Batch: 15/45, Loss: 5.2626, Throughput: 78.91 samples/sec
2025-03-26 04:42:38,935 - training - INFO - Memory: GPU 0: 3814.8MB allocated, 9070.0MB reserved
2025-03-26 04:42:38,935 - training - INFO - Epoch: 91/200000, Batch: 30/45, Loss: 5.2910, Throughput: 78.94 samples/sec
2025-03-26 04:42:49,011 - training - INFO - Epoch 91 completed in 32.07s. Average loss: 5.2645
2025-03-26 04:42:49,014 - training - INFO - Starting epoch 92/200000
2025-03-26 04:42:49,708 - training - INFO - Memory: GPU 0: 3812.1MB allocated, 9194.0MB reserved
2025-03-26 04:42:49,708 - training - INFO - Epoch: 92/200000, Batch: 0/45, Loss: 5.2539, Throughput: 80.91 samples/sec
2025-03-26 04:43:00,454 - training - INFO - Memory: GPU 0: 3808.0MB allocated, 9064.0MB reserved
2025-03-26 04:43:00,454 - training - INFO - Epoch: 92/200000, Batch: 15/45, Loss: 5.2065, Throughput: 78.33 samples/sec
2025-03-26 04:43:10,881 - training - INFO - Memory: GPU 0: 3809.3MB allocated, 9064.0MB reserved
2025-03-26 04:43:10,882 - training - INFO - Epoch: 92/200000, Batch: 30/45, Loss: 5.2512, Throughput: 79.40 samples/sec
2025-03-26 04:43:20,764 - training - INFO - Epoch 92 completed in 31.75s. Average loss: 5.2857
2025-03-26 04:43:20,767 - training - INFO - Starting epoch 93/200000
2025-03-26 04:43:21,455 - training - INFO - Memory: GPU 0: 3809.5MB allocated, 9190.0MB reserved
2025-03-26 04:43:21,455 - training - INFO - Epoch: 93/200000, Batch: 0/45, Loss: 5.3798, Throughput: 81.56 samples/sec
2025-03-26 04:43:32,208 - training - INFO - Memory: GPU 0: 3815.5MB allocated, 9088.0MB reserved
2025-03-26 04:43:32,208 - training - INFO - Epoch: 93/200000, Batch: 15/45, Loss: 5.2910, Throughput: 78.32 samples/sec
2025-03-26 04:43:42,669 - training - INFO - Memory: GPU 0: 3813.8MB allocated, 9088.0MB reserved
2025-03-26 04:43:42,669 - training - INFO - Epoch: 93/200000, Batch: 30/45, Loss: 5.3082, Throughput: 79.27 samples/sec
2025-03-26 04:43:52,553 - training - INFO - Epoch 93 completed in 31.79s. Average loss: 5.2693
2025-03-26 04:43:52,556 - training - INFO - Starting epoch 94/200000
2025-03-26 04:43:53,239 - training - INFO - Memory: GPU 0: 3812.4MB allocated, 9212.0MB reserved
2025-03-26 04:43:53,240 - training - INFO - Epoch: 94/200000, Batch: 0/45, Loss: 5.2686, Throughput: 82.18 samples/sec
2025-03-26 04:44:04,121 - training - INFO - Memory: GPU 0: 3816.7MB allocated, 9074.0MB reserved
2025-03-26 04:44:04,122 - training - INFO - Epoch: 94/200000, Batch: 15/45, Loss: 5.2560, Throughput: 77.48 samples/sec
2025-03-26 04:44:14,720 - training - INFO - Memory: GPU 0: 3811.9MB allocated, 9074.0MB reserved
2025-03-26 04:44:14,721 - training - INFO - Epoch: 94/200000, Batch: 30/45, Loss: 5.2638, Throughput: 78.33 samples/sec
2025-03-26 04:44:24,697 - training - INFO - Epoch 94 completed in 32.14s. Average loss: 5.2643
2025-03-26 04:44:24,701 - training - INFO - Starting epoch 95/200000
2025-03-26 04:44:25,422 - training - INFO - Memory: GPU 0: 3815.9MB allocated, 9200.0MB reserved
2025-03-26 04:44:25,423 - training - INFO - Epoch: 95/200000, Batch: 0/45, Loss: 4.7833, Throughput: 77.69 samples/sec
2025-03-26 04:44:36,295 - training - INFO - Memory: GPU 0: 3813.9MB allocated, 9076.0MB reserved
2025-03-26 04:44:36,295 - training - INFO - Epoch: 95/200000, Batch: 15/45, Loss: 5.2496, Throughput: 77.29 samples/sec
2025-03-26 04:44:46,973 - training - INFO - Memory: GPU 0: 3811.2MB allocated, 9078.0MB reserved
2025-03-26 04:44:46,974 - training - INFO - Epoch: 95/200000, Batch: 30/45, Loss: 5.2601, Throughput: 77.95 samples/sec
2025-03-26 04:44:56,944 - training - INFO - Epoch 95 completed in 32.24s. Average loss: 5.2545
2025-03-26 04:44:56,948 - training - INFO - Starting epoch 96/200000
2025-03-26 04:44:57,637 - training - INFO - Memory: GPU 0: 3812.9MB allocated, 9202.0MB reserved
2025-03-26 04:44:57,637 - training - INFO - Epoch: 96/200000, Batch: 0/45, Loss: 5.5976, Throughput: 81.29 samples/sec
2025-03-26 04:45:08,542 - training - INFO - Memory: GPU 0: 3817.3MB allocated, 9078.0MB reserved
2025-03-26 04:45:08,542 - training - INFO - Epoch: 96/200000, Batch: 15/45, Loss: 5.2312, Throughput: 77.28 samples/sec
2025-03-26 04:45:19,161 - training - INFO - Memory: GPU 0: 3811.2MB allocated, 9078.0MB reserved
2025-03-26 04:45:19,162 - training - INFO - Epoch: 96/200000, Batch: 30/45, Loss: 5.2772, Throughput: 78.15 samples/sec
2025-03-26 04:45:29,086 - training - INFO - Epoch 96 completed in 32.14s. Average loss: 5.2567
2025-03-26 04:45:29,089 - training - INFO - Starting epoch 97/200000
2025-03-26 04:45:29,774 - training - INFO - Memory: GPU 0: 3812.8MB allocated, 9202.0MB reserved
2025-03-26 04:45:29,775 - training - INFO - Epoch: 97/200000, Batch: 0/45, Loss: 5.4046, Throughput: 81.92 samples/sec
2025-03-26 04:45:40,585 - training - INFO - Memory: GPU 0: 3811.1MB allocated, 9068.0MB reserved
2025-03-26 04:45:40,585 - training - INFO - Epoch: 97/200000, Batch: 15/45, Loss: 5.2390, Throughput: 77.95 samples/sec
2025-03-26 04:45:51,107 - training - INFO - Memory: GPU 0: 3814.1MB allocated, 9070.0MB reserved
2025-03-26 04:45:51,107 - training - INFO - Epoch: 97/200000, Batch: 30/45, Loss: 5.1797, Throughput: 78.85 samples/sec
2025-03-26 04:46:01,048 - training - INFO - Epoch 97 completed in 31.96s. Average loss: 5.2367
2025-03-26 04:46:01,051 - training - INFO - Starting epoch 98/200000
2025-03-26 04:46:01,746 - training - INFO - Memory: GPU 0: 3810.7MB allocated, 9194.0MB reserved
2025-03-26 04:46:01,746 - training - INFO - Epoch: 98/200000, Batch: 0/45, Loss: 5.5252, Throughput: 80.82 samples/sec
2025-03-26 04:46:12,560 - training - INFO - Memory: GPU 0: 3811.5MB allocated, 9090.0MB reserved
2025-03-26 04:46:12,561 - training - INFO - Epoch: 98/200000, Batch: 15/45, Loss: 5.1837, Throughput: 77.86 samples/sec
2025-03-26 04:46:23,238 - training - INFO - Memory: GPU 0: 3815.0MB allocated, 9090.0MB reserved
2025-03-26 04:46:23,238 - training - INFO - Epoch: 98/200000, Batch: 30/45, Loss: 5.2143, Throughput: 78.25 samples/sec
2025-03-26 04:46:33,268 - training - INFO - Epoch 98 completed in 32.22s. Average loss: 5.2320
2025-03-26 04:46:33,271 - training - INFO - Starting epoch 99/200000
2025-03-26 04:46:33,955 - training - INFO - Memory: GPU 0: 3811.9MB allocated, 9214.0MB reserved
2025-03-26 04:46:33,955 - training - INFO - Epoch: 99/200000, Batch: 0/45, Loss: 5.1812, Throughput: 82.00 samples/sec
2025-03-26 04:46:44,862 - training - INFO - Memory: GPU 0: 3809.8MB allocated, 9068.0MB reserved
2025-03-26 04:46:44,862 - training - INFO - Epoch: 99/200000, Batch: 15/45, Loss: 5.1989, Throughput: 77.31 samples/sec
2025-03-26 04:46:55,470 - training - INFO - Memory: GPU 0: 3813.0MB allocated, 9068.0MB reserved
2025-03-26 04:46:55,470 - training - INFO - Epoch: 99/200000, Batch: 30/45, Loss: 5.2197, Throughput: 78.20 samples/sec
2025-03-26 04:47:05,372 - training - INFO - Epoch 99 completed in 32.10s. Average loss: 5.2309
2025-03-26 04:47:05,375 - training - INFO - Starting epoch 100/200000
2025-03-26 04:47:06,056 - training - INFO - Memory: GPU 0: 3810.7MB allocated, 9194.0MB reserved
2025-03-26 04:47:06,056 - training - INFO - Epoch: 100/200000, Batch: 0/45, Loss: 4.9562, Throughput: 82.43 samples/sec
2025-03-26 04:47:16,907 - training - INFO - Memory: GPU 0: 3810.0MB allocated, 9066.0MB reserved
2025-03-26 04:47:16,907 - training - INFO - Epoch: 100/200000, Batch: 15/45, Loss: 5.1783, Throughput: 77.71 samples/sec
2025-03-26 04:47:27,430 - training - INFO - Memory: GPU 0: 3810.4MB allocated, 9066.0MB reserved
2025-03-26 04:47:27,430 - training - INFO - Epoch: 100/200000, Batch: 30/45, Loss: 5.2403, Throughput: 78.72 samples/sec
2025-03-26 04:47:37,384 - training - INFO - Epoch 100 completed in 32.01s. Average loss: 5.2340
2025-03-26 04:47:37,387 - training - INFO - Starting validation...
2025-03-26 04:47:37,696 - training - INFO - Validation Loss: 6.2142
2025-03-26 04:47:37,697 - training - INFO - Validation loss improved from previous (6.2177 to 6.2142) but not better than best (6.2134). Counter reduced to 0.
2025-03-26 04:47:37,926 - training - INFO - Starting epoch 101/200000
2025-03-26 04:47:38,637 - training - INFO - Memory: GPU 0: 3818.0MB allocated, 8486.0MB reserved
2025-03-26 04:47:38,637 - training - INFO - Epoch: 101/200000, Batch: 0/45, Loss: 5.2917, Throughput: 78.96 samples/sec
2025-03-26 04:47:49,337 - training - INFO - Memory: GPU 0: 3818.0MB allocated, 9172.0MB reserved
2025-03-26 04:47:49,337 - training - INFO - Epoch: 101/200000, Batch: 15/45, Loss: 5.2466, Throughput: 78.53 samples/sec
2025-03-26 04:47:59,833 - training - INFO - Memory: GPU 0: 3815.7MB allocated, 9172.0MB reserved
2025-03-26 04:47:59,834 - training - INFO - Epoch: 101/200000, Batch: 30/45, Loss: 5.3003, Throughput: 79.25 samples/sec
2025-03-26 04:48:09,724 - training - INFO - Epoch 101 completed in 31.80s. Average loss: 5.2144
2025-03-26 04:48:09,728 - training - INFO - Starting epoch 102/200000
2025-03-26 04:48:10,414 - training - INFO - Memory: GPU 0: 3813.6MB allocated, 9300.0MB reserved
2025-03-26 04:48:10,415 - training - INFO - Epoch: 102/200000, Batch: 0/45, Loss: 5.0341, Throughput: 81.69 samples/sec
2025-03-26 04:48:21,252 - training - INFO - Memory: GPU 0: 3816.1MB allocated, 9078.0MB reserved
2025-03-26 04:48:21,252 - training - INFO - Epoch: 102/200000, Batch: 15/45, Loss: 5.1754, Throughput: 77.76 samples/sec
2025-03-26 04:48:31,838 - training - INFO - Memory: GPU 0: 3816.1MB allocated, 9078.0MB reserved
2025-03-26 04:48:31,839 - training - INFO - Epoch: 102/200000, Batch: 30/45, Loss: 5.1843, Throughput: 78.52 samples/sec
2025-03-26 04:48:41,840 - training - INFO - Epoch 102 completed in 32.11s. Average loss: 5.2348
2025-03-26 04:48:41,844 - training - INFO - Starting epoch 103/200000
2025-03-26 04:48:42,560 - training - INFO - Memory: GPU 0: 3814.7MB allocated, 9204.0MB reserved
2025-03-26 04:48:42,560 - training - INFO - Epoch: 103/200000, Batch: 0/45, Loss: 5.2428, Throughput: 78.42 samples/sec
2025-03-26 04:48:53,398 - training - INFO - Memory: GPU 0: 3813.1MB allocated, 9070.0MB reserved
2025-03-26 04:48:53,398 - training - INFO - Epoch: 103/200000, Batch: 15/45, Loss: 5.1452, Throughput: 77.56 samples/sec
2025-03-26 04:49:03,982 - training - INFO - Memory: GPU 0: 3811.6MB allocated, 9070.0MB reserved
2025-03-26 04:49:03,983 - training - INFO - Epoch: 103/200000, Batch: 30/45, Loss: 5.1972, Throughput: 78.42 samples/sec
2025-03-26 04:49:13,944 - training - INFO - Epoch 103 completed in 32.10s. Average loss: 5.2099
2025-03-26 04:49:13,947 - training - INFO - Starting epoch 104/200000
2025-03-26 04:49:14,636 - training - INFO - Memory: GPU 0: 3817.8MB allocated, 9194.0MB reserved
2025-03-26 04:49:14,636 - training - INFO - Epoch: 104/200000, Batch: 0/45, Loss: 5.3310, Throughput: 81.44 samples/sec
2025-03-26 04:49:25,444 - training - INFO - Memory: GPU 0: 3815.4MB allocated, 9082.0MB reserved
2025-03-26 04:49:25,444 - training - INFO - Epoch: 104/200000, Batch: 15/45, Loss: 5.2351, Throughput: 77.94 samples/sec
2025-03-26 04:49:36,008 - training - INFO - Memory: GPU 0: 3813.7MB allocated, 9082.0MB reserved
2025-03-26 04:49:36,009 - training - INFO - Epoch: 104/200000, Batch: 30/45, Loss: 5.1905, Throughput: 78.69 samples/sec
2025-03-26 04:49:45,887 - training - INFO - Epoch 104 completed in 31.94s. Average loss: 5.2031
2025-03-26 04:49:45,890 - training - INFO - Starting epoch 105/200000
2025-03-26 04:49:46,578 - training - INFO - Memory: GPU 0: 3814.4MB allocated, 9206.0MB reserved
2025-03-26 04:49:46,578 - training - INFO - Epoch: 105/200000, Batch: 0/45, Loss: 5.3073, Throughput: 81.54 samples/sec
2025-03-26 04:49:57,470 - training - INFO - Memory: GPU 0: 3819.3MB allocated, 9078.0MB reserved
2025-03-26 04:49:57,471 - training - INFO - Epoch: 105/200000, Batch: 15/45, Loss: 5.2097, Throughput: 77.39 samples/sec
2025-03-26 04:50:08,167 - training - INFO - Memory: GPU 0: 3815.4MB allocated, 9080.0MB reserved
2025-03-26 04:50:08,167 - training - INFO - Epoch: 105/200000, Batch: 30/45, Loss: 5.2332, Throughput: 77.94 samples/sec
2025-03-26 04:50:18,121 - training - INFO - Epoch 105 completed in 32.23s. Average loss: 5.2120
2025-03-26 04:50:18,124 - training - INFO - Starting epoch 106/200000
2025-03-26 04:50:18,835 - training - INFO - Memory: GPU 0: 3816.3MB allocated, 9204.0MB reserved
2025-03-26 04:50:18,836 - training - INFO - Epoch: 106/200000, Batch: 0/45, Loss: 4.6207, Throughput: 78.96 samples/sec
2025-03-26 04:50:29,700 - training - INFO - Memory: GPU 0: 3813.8MB allocated, 9064.0MB reserved
2025-03-26 04:50:29,700 - training - INFO - Epoch: 106/200000, Batch: 15/45, Loss: 5.0975, Throughput: 77.42 samples/sec
2025-03-26 04:50:40,374 - training - INFO - Memory: GPU 0: 3812.1MB allocated, 9066.0MB reserved
2025-03-26 04:50:40,375 - training - INFO - Epoch: 106/200000, Batch: 30/45, Loss: 5.1414, Throughput: 78.03 samples/sec
2025-03-26 04:50:50,258 - training - INFO - Epoch 106 completed in 32.13s. Average loss: 5.1971
2025-03-26 04:50:50,262 - training - INFO - Starting epoch 107/200000
2025-03-26 04:50:50,950 - training - INFO - Memory: GPU 0: 3819.2MB allocated, 9190.0MB reserved
2025-03-26 04:50:50,950 - training - INFO - Epoch: 107/200000, Batch: 0/45, Loss: 4.9246, Throughput: 81.41 samples/sec
2025-03-26 04:51:01,934 - training - INFO - Memory: GPU 0: 3818.1MB allocated, 9078.0MB reserved
2025-03-26 04:51:01,934 - training - INFO - Epoch: 107/200000, Batch: 15/45, Loss: 5.1765, Throughput: 76.78 samples/sec
2025-03-26 04:51:12,731 - training - INFO - Memory: GPU 0: 3815.7MB allocated, 9080.0MB reserved
2025-03-26 04:51:12,731 - training - INFO - Epoch: 107/200000, Batch: 30/45, Loss: 5.1714, Throughput: 77.27 samples/sec
2025-03-26 04:51:22,862 - training - INFO - Epoch 107 completed in 32.60s. Average loss: 5.1927
2025-03-26 04:51:22,865 - training - INFO - Starting epoch 108/200000
2025-03-26 04:51:23,567 - training - INFO - Memory: GPU 0: 3819.5MB allocated, 9204.0MB reserved
2025-03-26 04:51:23,567 - training - INFO - Epoch: 108/200000, Batch: 0/45, Loss: 5.1929, Throughput: 79.98 samples/sec
2025-03-26 04:51:34,463 - training - INFO - Memory: GPU 0: 3815.8MB allocated, 9072.0MB reserved
2025-03-26 04:51:34,463 - training - INFO - Epoch: 108/200000, Batch: 15/45, Loss: 5.2139, Throughput: 77.27 samples/sec
2025-03-26 04:51:45,119 - training - INFO - Memory: GPU 0: 3813.7MB allocated, 9074.0MB reserved
2025-03-26 04:51:45,120 - training - INFO - Epoch: 108/200000, Batch: 30/45, Loss: 5.2008, Throughput: 78.01 samples/sec
2025-03-26 04:51:55,114 - training - INFO - Epoch 108 completed in 32.25s. Average loss: 5.1828
2025-03-26 04:51:55,117 - training - INFO - Starting epoch 109/200000
2025-03-26 04:51:55,818 - training - INFO - Memory: GPU 0: 3813.7MB allocated, 9198.0MB reserved
2025-03-26 04:51:55,818 - training - INFO - Epoch: 109/200000, Batch: 0/45, Loss: 4.9971, Throughput: 80.06 samples/sec
2025-03-26 04:52:06,710 - training - INFO - Memory: GPU 0: 3813.2MB allocated, 9070.0MB reserved
2025-03-26 04:52:06,710 - training - INFO - Epoch: 109/200000, Batch: 15/45, Loss: 5.0892, Throughput: 77.31 samples/sec
2025-03-26 04:52:17,276 - training - INFO - Memory: GPU 0: 3815.0MB allocated, 9072.0MB reserved
2025-03-26 04:52:17,277 - training - INFO - Epoch: 109/200000, Batch: 30/45, Loss: 5.1776, Throughput: 78.35 samples/sec
2025-03-26 04:52:27,170 - training - INFO - Epoch 109 completed in 32.05s. Average loss: 5.1854
2025-03-26 04:52:27,174 - training - INFO - Starting epoch 110/200000
2025-03-26 04:52:27,875 - training - INFO - Memory: GPU 0: 3816.1MB allocated, 9196.0MB reserved
2025-03-26 04:52:27,875 - training - INFO - Epoch: 110/200000, Batch: 0/45, Loss: 5.1430, Throughput: 80.04 samples/sec
2025-03-26 04:52:38,656 - training - INFO - Memory: GPU 0: 3815.3MB allocated, 9064.0MB reserved
2025-03-26 04:52:38,657 - training - INFO - Epoch: 110/200000, Batch: 15/45, Loss: 5.1450, Throughput: 78.03 samples/sec
2025-03-26 04:52:49,297 - training - INFO - Memory: GPU 0: 3814.3MB allocated, 9064.0MB reserved
2025-03-26 04:52:49,297 - training - INFO - Epoch: 110/200000, Batch: 30/45, Loss: 5.1601, Throughput: 78.48 samples/sec
2025-03-26 04:52:59,255 - training - INFO - Epoch 110 completed in 32.08s. Average loss: 5.1731
2025-03-26 04:52:59,258 - training - INFO - Starting validation...
2025-03-26 04:52:59,568 - training - INFO - Validation Loss: 6.2472
2025-03-26 04:52:59,568 - training - INFO - Validation loss did not improve. Counter: 1/10
2025-03-26 04:52:59,806 - training - INFO - Starting epoch 111/200000
2025-03-26 04:53:00,505 - training - INFO - Memory: GPU 0: 3815.4MB allocated, 8568.0MB reserved
2025-03-26 04:53:00,506 - training - INFO - Epoch: 111/200000, Batch: 0/45, Loss: 5.1442, Throughput: 80.20 samples/sec
2025-03-26 04:53:11,188 - training - INFO - Memory: GPU 0: 3818.8MB allocated, 9046.0MB reserved
2025-03-26 04:53:11,188 - training - INFO - Epoch: 111/200000, Batch: 15/45, Loss: 5.2269, Throughput: 78.74 samples/sec
2025-03-26 04:53:21,737 - training - INFO - Memory: GPU 0: 3818.9MB allocated, 9046.0MB reserved
2025-03-26 04:53:21,737 - training - INFO - Epoch: 111/200000, Batch: 30/45, Loss: 5.2072, Throughput: 79.17 samples/sec
2025-03-26 04:53:25,608 - training - INFO - Training completed successfully.
